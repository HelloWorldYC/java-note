(window.webpackJsonp=window.webpackJsonp||[]).push([[28],{371:function(t,s,a){t.exports=a.p+"assets/img/MySQL和ES中概念对比.fcb1b811.png"},372:function(t,s,a){t.exports=a.p+"assets/img/正向索引和倒排索引.d4e467b0.png"},676:function(t,s,a){"use strict";a.r(s);var n=a(18),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h2",{attrs:{id:"elasticsearch入门"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch入门"}},[t._v("#")]),t._v(" Elasticsearch入门")]),t._v(" "),n("ul",[n("li",[t._v("Elasticsearch简介\n"),n("ul",[n("li",[t._v("一个分布式的（多台服务器进行部署）、Restful风格（设计风格）的"),n("strong",[t._v("搜索引擎")])]),t._v(" "),n("li",[t._v("支持对各种类型的数据的检索")]),t._v(" "),n("li",[t._v("搜索速度快，可以提供实时的搜索服务")]),t._v(" "),n("li",[t._v("便于水平扩展，每秒可以处理PB级海量数据")]),t._v(" "),n("li",[t._v("可以理解为一个特殊的数据库，要利用ES需要将数据在ES里存一份")])])]),t._v(" "),n("li",[t._v("E lasticsearch术语（与mysql对比着看），在ES6.0之后要废弃类型，一个索引相当于一张表\n"),n("ul",[n("li",[n("strong",[t._v("索引")]),t._v("（database）、"),n("strong",[t._v("类型")]),t._v("（table）、"),n("strong",[t._v("文档")]),t._v("(一条数据)、"),n("strong",[t._v("字段")]),t._v("(一列)")]),t._v(" "),n("li",[n("strong",[t._v("集群")]),t._v("、"),n("strong",[t._v("节点")]),t._v("(集群中的每台服务器)、"),n("strong",[t._v("分片")]),t._v("(对索引的拆分)、"),n("strong",[t._v("副本")]),t._v("(对分片的备份)")])])]),t._v(" "),n("li",[t._v("Elasticsearch使用\n"),n("ul",[n("li",[t._v("在搜索时会先将搜索的条件进行分词，再将词条进行匹配")]),t._v(" "),n("li",[t._v("9200是http访问的端口，9300是TCP端口")])])])]),t._v(" "),n("h2",{attrs:{id:"spring-整合-elasticsearch"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#spring-整合-elasticsearch"}},[t._v("#")]),t._v(" spring 整合 Elasticsearch")]),t._v(" "),n("ul",[n("li",[t._v("引入依赖\n"),n("ul",[n("li",[t._v("spring-boot-starter-data-elasticsearch")])])]),t._v(" "),n("li",[t._v("配置 Elasticsearch\n"),n("ul",[n("li",[t._v("cluster-name、cluster-nodes")])])]),t._v(" "),n("li",[t._v("Spring Data Elasticsearch\n"),n("ul",[n("li",[t._v("ElasticsearchTemplate")]),t._v(" "),n("li",[t._v("ElasticsearchRepository")])])]),t._v(" "),n("li",[t._v("注意点\n"),n("ul",[n("li",[t._v("redis底层依赖 netty，而 ES 底层也依赖 netty，所以需要设置 NettyUtils 的 setAvailableProcessor 避免 ES 报错")])])])]),t._v(" "),n("h2",{attrs:{id:"初识-elasticsearch"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#初识-elasticsearch"}},[t._v("#")]),t._v(" 初识 Elasticsearch")]),t._v(" "),n("h3",{attrs:{id:"什么是-elasticsearch"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#什么是-elasticsearch"}},[t._v("#")]),t._v(" 什么是 Elasticsearch")]),t._v(" "),n("p",[t._v("Elasticsearch 是一款非常强大的开源搜索引擎，可以帮助我们从海量数据中快速找到需要的内容。")]),t._v(" "),n("p",[t._v("Elasticsearch 结合 Kibana、Logstash、Beats，就是 Elastic Stack (ELK)。ELK 被广泛应用在日志数据分析、实时监控等领域。其中，")]),t._v(" "),n("ul",[n("li",[t._v("Elasticsearch 是 ELK 的核心，负责存储、搜索、分析数据。")]),t._v(" "),n("li",[t._v("Kibana 用于数据可视化。")]),t._v(" "),n("li",[t._v("Logstash、Beats 用于数据抓取。")])]),t._v(" "),n("h3",{attrs:{id:"什么是-lucence"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#什么是-lucence"}},[t._v("#")]),t._v(" 什么是 Lucence")]),t._v(" "),n("p",[t._v("Lucene 是一个 Java 语言的搜索引擎类库，是 Apache 公司的顶级项目，由 DougCutting 于 1999 年研发。"),n("br"),t._v("\nLucene 的优势：易扩展、高性能（基于倒排索引）。"),n("br"),t._v("\nLucene 的缺点：只限于 Java 语言开发、学习曲线陡峭、不支持水平扩展。")]),t._v(" "),n("p",[t._v("2004年 Shay Banon 基于 Lucene 开发了 Compass。"),n("br"),t._v("\n2010年 Shay Banon 重写了 Compass，取名为 Elasticsearch。")]),t._v(" "),n("p",[t._v("相比于 Lucene，Elasticsearch 具备下列优势：")]),t._v(" "),n("ul",[n("li",[t._v("支持分布式，可水平扩展。")]),t._v(" "),n("li",[t._v("提供 Restful 接口，可被任何语言调用。")])]),t._v(" "),n("h3",{attrs:{id:"文档、词条、索引、映射"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#文档、词条、索引、映射"}},[t._v("#")]),t._v(" 文档、词条、索引、映射")]),t._v(" "),n("p",[t._v("在 ES 中，有几个概念需要了解一下，跟传统的数据库 MySQL 不一样。")]),t._v(" "),n("ul",[n("li",[t._v("文档：Elasticsearch 是面向文档存储的，每一条数据就是一个文档，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为 JSON 格式后存储在 Elasticsearch 中。")]),t._v(" "),n("li",[t._v("词条： 对文档中的内容分词，得到的词语就是词条。")]),t._v(" "),n("li",[t._v("索引：相同类型的文档的集合。")]),t._v(" "),n("li",[t._v("映射：索引中文档的字段约束信息，类似表的结构约束。")])]),t._v(" "),n("div",{attrs:{align:"center"}},[n("img",{attrs:{src:a(371),width:"100%"}})]),t._v(" "),n("h3",{attrs:{id:"正向索引和倒排索引"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#正向索引和倒排索引"}},[t._v("#")]),t._v(" 正向索引和倒排索引")]),t._v(" "),n("p",[t._v("传统数据库是采用正向索引的，但 Elasticsearch 是按照倒排索引。这两种索引的区别如下：")]),t._v(" "),n("ul",[n("li",[t._v("正向索引是按照 "),n("strong",[t._v("文档-词条")]),t._v(" 的方式组织的索引，一般是基于文档 id 创建的索引。每个文档都包含了它包含的词项以及相关的其他信息，比如词条的位置、频率等。这种结构更适合用于检索某个文档的内容，传统数据库如 MySQL 采用的就是这种。")]),t._v(" "),n("li",[t._v("倒排索引是按照 "),n("strong",[t._v("词条-文档")]),t._v(" 的方式组织的索引，基于词条创建索引。对于每个词条，记录包含该词条的所有文档信息。这种结构更适合用于搜索某个词条在哪些文档中出现。")])]),t._v(" "),n("div",{attrs:{align:"center"}},[n("img",{attrs:{src:a(372),width:"100%"}})]),t._v(" "),n("br"),t._v(" "),n("p",[t._v("倒排索引中包含两部分内容：")]),t._v(" "),n("ul",[n("li",[t._v("词条词典（Term Dictionary）：记录所有词条，以及词条与倒排列表（Posting List）之间的关系，会给词条创建索引，提高查询和插入效率。")]),t._v(" "),n("li",[t._v("倒排列表（Posting List）：记录词条所在的文档 id、词条出现频率、词条在文档中的位置等信息。\n"),n("ul",[n("li",[t._v("文档 id：用于快速获取文档。")]),t._v(" "),n("li",[t._v("词条频率(TF)：词条在文档中出现的次数，用于评分。")])])])]),t._v(" "),n("p",[t._v("倒排索引的搜索流程如下：")]),t._v(" "),n("ol",[n("li",[t._v("对用户输入内容分词，得到词条。")]),t._v(" "),n("li",[t._v("根据词条在倒排索引中查找，可以得到包含词条的文档 id。")]),t._v(" "),n("li",[t._v("根据文档 id 到正向索引中查找具体文档。")])]),t._v(" "),n("h3",{attrs:{id:"分词器"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#分词器"}},[t._v("#")]),t._v(" 分词器")]),t._v(" "),n("p",[t._v("es 在创建倒排索引的时候需要对文档分词；在搜索时，需要对用户输入内容分词。它默认的分词规则对中文处理不太友好，可以在 kibana 中测试：")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[t._v("POST "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("_analyze\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"analyzer"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"standard"')]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"text"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"分词器测试"')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("其中，")]),t._v(" "),n("ul",[n("li",[n("code",[t._v("POST")]),t._v("：请求方式")]),t._v(" "),n("li",[n("code",[t._v("/-analyzer")]),t._v("：请求路径，这里省略了 ip 和 端口，由 kibana 帮我们补充")]),t._v(" "),n("li",[t._v("请求参数：json 风格，"),n("code",[t._v("analyzer")]),t._v(" 是分词器类型，这里是默认的 "),n("code",[t._v("standard")]),t._v(" 分词器，"),n("code",[t._v("text")]),t._v(" 是要分词的内容。")])]),t._v(" "),n("p",[t._v("由于默认的 "),n("code",[t._v("standard")]),t._v(" 分词器对中文不太友好，因此处理中文分词，一般会使用 IK 分词器。它的安装上网查即可，这里就不提了。"),n("br"),t._v("\nIK 分词器包含两种模式：")]),t._v(" "),n("ul",[n("li",[n("code",[t._v("ik_smart")]),t._v("：按词切分，不重复包含字，最少切分，粗粒度。例如，“分词器测试” 会被分为 “分词器” 和 “测试” 这两个词条。")]),t._v(" "),n("li",[n("code",[t._v("ik_max_word")]),t._v("：按词切分后，还按字切分，最细切分，细粒度。例如，“分词器测试” 会被分词为 “分词器”、“分词”、“分”、“词”、“器”、“测试”、“测”、“试” 这么多个词条。")])]),t._v(" "),n("h4",{attrs:{id:"ik-分词器-扩展词库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#ik-分词器-扩展词库"}},[t._v("#")]),t._v(" IK 分词器——扩展词库")]),t._v(" "),n("p",[t._v("除了现有的词库，我们还可以扩展 IK 分词器的词库，只需要修改 IK 分词器目录中的 config 目录中的 IkAnalyzer.cfg.xml 文件：")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("properties")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("comment")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("IK Analyzer 扩展配置"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("comment")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典--\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("entry")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("key")]),n("span",{pre:!0,attrs:{class:"token attr-value"}},[n("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("ext_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("ext.dic"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("entry")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("properties")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("然后在 ext.dic 文件中，添加想要扩展的词语即可。")]),t._v(" "),n("h4",{attrs:{id:"ik-分词器-停用词库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#ik-分词器-停用词库"}},[t._v("#")]),t._v(" IK 分词器——停用词库")]),t._v(" "),n("p",[t._v("我们还可以禁止某些敏感词条，同样是在 IkAnalyzer.cfg.xml 文件中修改：")]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("properties")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("comment")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("IK Analyzer 扩展配置"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("comment")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n         "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!--用户可以在这里配置自己的扩展停止词字典  *** 添加停用词词典--\x3e")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("entry")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("key")]),n("span",{pre:!0,attrs:{class:"token attr-value"}},[n("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("ext_stopwords"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("stopword.dic"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("entry")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("properties")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("p",[t._v("然后在 ext_stopword.dic 文件中添加想要禁止的敏感词即可。")]),t._v(" "),n("h2",{attrs:{id:"索引库操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#索引库操作"}},[t._v("#")]),t._v(" 索引库操作")]),t._v(" "),n("h3",{attrs:{id:"mapping-属性"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#mapping-属性"}},[t._v("#")]),t._v(" mapping 属性")]),t._v(" "),n("p",[t._v("mapping 是对索引库中文档的约束，常见的 mapping 属性包括：")]),t._v(" "),n("ul",[n("li",[t._v("type：字段数据类型，常见的简单类型有：\n"),n("ul",[n("li",[t._v("字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip 地址）")]),t._v(" "),n("li",[t._v("数值：long、integer、short、byte、double、float")]),t._v(" "),n("li",[t._v("布尔：boolean")]),t._v(" "),n("li",[t._v("日期：date")]),t._v(" "),n("li",[t._v("对象：object")])])]),t._v(" "),n("li",[t._v("index：是否创建索引，默认为 true")]),t._v(" "),n("li",[t._v("analyzer：使用哪种分词器")]),t._v(" "),n("li",[t._v("properties：该字段的子字段")])]),t._v(" "),n("p",[t._v("以下面的字段为例：")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"age"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"weight"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("52.1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"isMarried"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"info"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mapping属性例子"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"email"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"myc@itcast.cn"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"score"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("99.1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("99.5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("98.9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"firstName"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"彦祖"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"lastName"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"吴"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("对应每个字段的映射应为：")]),t._v(" "),n("ul",[n("li",[t._v("age：类型为 integer；参与搜索，因此需要 index 为 true；无需分词器。")]),t._v(" "),n("li",[t._v("weight：类型为float；参与搜索，因此需要 index 为 true；无需分词器。")]),t._v(" "),n("li",[t._v("isMarried：类型为 boolean；参与搜索，因此需要 index 为 true；无需分词器。")]),t._v(" "),n("li",[t._v("info：类型为字符串，需要分词，因此是 text；参与搜索，因此需要 index 为 true；分词器可以用ik_smart。")]),t._v(" "),n("li",[t._v("email：类型为字符串，但是不需要分词，因此类型是 keyword；不参与搜索，因此需要 index 为false；无需分词器。")]),t._v(" "),n("li",[t._v("score：虽然是数组，但是只看元素的类型，类型为 float；参与搜索，因此需要 index 为 true；无需分词器。")]),t._v(" "),n("li",[t._v("name：类型为 object，需要定义多个子属性。\n"),n("ul",[n("li",[t._v("name.firstName：类型为字符串，但是不需要分词，因此是 keyword；参与搜索，因此需要 index 为 true；无需分词器。")]),t._v(" "),n("li",[t._v("name.lastName：类型为字符串，不需要分词，类型是 keyword；参与搜索，因此需要 index 为 true；无需分词器。")])])])]),t._v(" "),n("h3",{attrs:{id:"创建索引库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#创建索引库"}},[t._v("#")]),t._v(" 创建索引库")]),t._v(" "),n("p",[t._v("ES 中通过 Restful 请求操作索引库和文档。请求内容用 DSL (Domain Specific Language) 语句来表示。")]),t._v(" "),n("p",[t._v("创建索引库和 mapping 的 DSL 语法如下：")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[t._v("PUT /索引库名称\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"mappings"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"properties"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"字段名1"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"text"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"analyzer"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ik_smart"')]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"字段名2"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"keyword"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"index"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"false"')]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"字段名3"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"properties"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"子字段"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"keyword"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"index"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"false"')]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...略")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h3",{attrs:{id:"查询索引库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#查询索引库"}},[t._v("#")]),t._v(" 查询索引库")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[t._v("GET /索引库名\n")])])]),n("h3",{attrs:{id:"修改索引库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#修改索引库"}},[t._v("#")]),t._v(" 修改索引库")]),t._v(" "),n("p",[t._v("倒排索引结构虽然不复杂，但是一旦数据结构改变（比如改变了分词器），就需要重新创建倒排索引，这简直是灾难。因此索引库一旦创建，无法修改 mapping。"),n("br"),t._v("\n虽然无法修改 mapping 中已有的字段，但是却允许添加新的字段到 mapping 中，因为不会对倒排索引产生影响。")]),t._v(" "),n("p",[t._v("添加新字段：")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[t._v("PUT /索引库名/_mapping\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"properties"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"新字段名"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"type"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"integer"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h3",{attrs:{id:"删除索引库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#删除索引库"}},[t._v("#")]),t._v(" 删除索引库")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[t._v("DELETE /索引库名\n")])])]),n("h2",{attrs:{id:"文档操作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#文档操作"}},[t._v("#")]),t._v(" 文档操作")]),t._v(" "),n("h3",{attrs:{id:"新增文档"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#新增文档"}},[t._v("#")]),t._v(" 新增文档")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[t._v("POST /索引库名/_doc/文档id\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"字段1"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"值1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"字段2"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"值2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"字段3"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"子属性1"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"值3"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"子属性2"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"值4"')]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h3",{attrs:{id:"查询文档"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#查询文档"}},[t._v("#")]),t._v(" 查询文档")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[t._v("GET /索引库名/_doc/文档id\n")])])]),n("h3",{attrs:{id:"删除文档"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#删除文档"}},[t._v("#")]),t._v(" 删除文档")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[t._v("DELETE /索引库名/_doc/文档id\n")])])]),n("h3",{attrs:{id:"修改文档"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#修改文档"}},[t._v("#")]),t._v(" 修改文档")]),t._v(" "),n("p",[t._v("对于修改文档，有两种方式：")]),t._v(" "),n("ul",[n("li",[t._v("全量修改：直接覆盖原来的文档，其本质是先删除文档，再新建一个。值得注意的是，当 id 不存在时，虽然没有了删除操作，但新增操作还是会执行，此时修改操作就变成了新增操作。")]),t._v(" "),n("li",[t._v("增量修改：修改文档中的部分字段。")])]),t._v(" "),n("p",[t._v("对于全量修改，其语法是：")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[t._v("PUT /索引库名/_doc/文档id\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"字段1"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"值1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"字段2"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"值2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ... 略")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("对于增量修改，其语法是：")]),t._v(" "),n("div",{staticClass:"language-json extra-class"},[n("pre",{pre:!0,attrs:{class:"language-json"}},[n("code",[t._v("POST /索引库名/_update/文档id\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"doc"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n         "),n("span",{pre:!0,attrs:{class:"token property"}},[t._v('"字段名"')]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"新的值"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("注意：全量修改对应的是 "),n("code",[t._v("PUT")]),t._v(" 和 "),n("code",[t._v("_doc")]),t._v("，增量修改对应的是 "),n("code",[t._v("POST")]),t._v(" 和 "),n("code",[t._v("_update")]),t._v("。")]),t._v(" "),n("h3",{attrs:{id:"动态映射"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#动态映射"}},[t._v("#")]),t._v(" 动态映射")]),t._v(" "),n("p",[t._v("当我们向 ES 中插入文档时，如果文档中字段没有对应的 mapping，ES 会帮助我们字段设置 mapping，规则如下：")]),t._v(" "),n("ul",[n("li",[t._v("字符串：\n"),n("ul",[n("li",[t._v("日期格式字符串：mapping 为 date 类型。")]),t._v(" "),n("li",[t._v("普通字符串：mapping 为 text 类型，并添加 keyword 类型子字段。")])])]),t._v(" "),n("li",[t._v("布尔值：boolean")]),t._v(" "),n("li",[t._v("浮点数：float")]),t._v(" "),n("li",[t._v("整数：long")]),t._v(" "),n("li",[t._v("对象嵌套：object，并添加 properties。")]),t._v(" "),n("li",[t._v("数组，由数组中第一个非空类型决定。")]),t._v(" "),n("li",[t._v("空值：忽略。")])]),t._v(" "),n("h2",{attrs:{id:"restapi"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#restapi"}},[t._v("#")]),t._v(" RestAPI")]),t._v(" "),n("p",[t._v("ES 官方提供了各种不同语言的客户端，用来操作 ES。"),n("strong",[t._v("这些客户端的本质就是组装 DSL 语句，通过 HTTP 请求发送给 ES。")]),t._v(" 官方文档地址：https://www.elastic.co/guide/en/elasticsearch/client/index.html。")]),t._v(" "),n("p",[t._v("其中，Java Rest Client 包括了两种：")]),t._v(" "),n("ul",[n("li",[t._v("Java Low Level Rest Client")]),t._v(" "),n("li",[t._v("Java High Level Rest Client")])]),t._v(" "),n("h3",{attrs:{id:"初始化-restclient"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#初始化-restclient"}},[t._v("#")]),t._v(" 初始化 RestClient")]),t._v(" "),n("p",[t._v("在 ES 提供的 API 中，与 ES 一切交互都封装在一个名为 RestHighLevelClient 得到类中，要对 ES 进行操作，必须先完成这个对象的初始化，建立与 ES 的连接。")]),t._v(" "),n("p",[t._v("步骤如下：")]),t._v(" "),n("ol",[n("li",[t._v("引入 ES 的 RestHighLevelClient 依赖：")])]),t._v(" "),n("div",{staticClass:"language-xml extra-class"},[n("pre",{pre:!0,attrs:{class:"language-xml"}},[n("code",[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.elasticsearch.client"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("elasticsearch-rest-high-level-client"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("7.12.1"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token tag"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),n("ol",{attrs:{start:"2"}},[n("li",[t._v("初始化 RestHighLevelClient：")])]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RestHighLevelClient")]),t._v(" client "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RestHighLevelClient")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RestClient")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("builder")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HttpHost")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://192.168.150.101:9200"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("h3",{attrs:{id:"restclient-操作索引库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#restclient-操作索引库"}},[t._v("#")]),t._v(" RestClient 操作索引库")]),t._v(" "),n("h4",{attrs:{id:"restclient-创建索引库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#restclient-创建索引库"}},[t._v("#")]),t._v(" RestClient 创建索引库")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("createIndex")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IOException")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1.创建 Request 对象")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CreateIndexRequest")]),t._v(" request "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("CreateIndexRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hotel"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2.设置请求参数")]),t._v("\n    request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("source")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("MAPPING_TEMPLATE"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("XContentType")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("JSON"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 3.发送请求")]),t._v("\n    client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("indices")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RequestOptions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DEFAULT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("这里说明一下这三步：")]),t._v(" "),n("ol",[n("li",[t._v("创建 Request 对象。因为是创建索引库的操作，所以是 "),n("code",[t._v("CreateIndexRequest")]),t._v("。")]),t._v(" "),n("li",[t._v("设置请求参数。这里其实就是设置 DSL 的 JSON 参数部分，也就是 mapping 部分。因为 JSON 字符串很长，所以这里将其定义为 "),n("code",[t._v("MAPPING_TEMPLATE")]),t._v("，让代码看起来更加优雅。")]),t._v(" "),n("li",[t._v("发送请求。"),n("code",[t._v("client.indices()")]),t._v(" 方法返回值是 "),n("code",[t._v("indicesClient")]),t._v(" 类型，封装了所有与索引库操作相关的方法。")])]),t._v(" "),n("h4",{attrs:{id:"restclient-删除索引库"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#restclient-删除索引库"}},[t._v("#")]),t._v(" RestClient 删除索引库")]),t._v(" "),n("p",[t._v("类似的，RestClient 删除索引库的代码如下：")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testDeleteIndex")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IOException")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1. 创建 Request 对象")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DeleteIndexRequest")]),t._v(" request "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DeleteIndexRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hotel"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2. 发送请求")]),t._v("\n  client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("indices")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RequestOptions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DEFAULT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h4",{attrs:{id:"restclient-判断索引库是否存在"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#restclient-判断索引库是否存在"}},[t._v("#")]),t._v(" RestClient 判断索引库是否存在")]),t._v(" "),n("p",[t._v("判断索引库是否存在，本质就是查询，对应的 DSL 是 "),n("code",[t._v("GET /索引库")]),t._v("，用 RestClient 的步骤如下：")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testExitsIndex")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IOException")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("GetIndexRequest")]),t._v(" request "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("GetIndexRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hotel"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注意，这里是 exists() 方法，不是 get()")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("boolean")]),t._v(" exists "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("indices")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("exists")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RequestOptions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DEFAULT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("exists "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"索引库已经存在！"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"索引库不存在"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h3",{attrs:{id:"restclient-操作文档"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#restclient-操作文档"}},[t._v("#")]),t._v(" RestClient 操作文档")]),t._v(" "),n("p",[t._v("这里先总的说一下文档操作的基本步骤：")]),t._v(" "),n("ol",[n("li",[t._v("初始化 "),n("code",[t._v("RestHighLevelClient")])]),t._v(" "),n("li",[t._v("创建 xxxRequest。xxx 是 Index、Get、Update、Delete。")]),t._v(" "),n("li",[t._v("准备参数(Index 和 Update 时需要)")]),t._v(" "),n("li",[t._v("发送请求。调用 RestHighLevelClient.xxx() 方法，xxx 是 index、get、update、delete。")]),t._v(" "),n("li",[t._v("解析结果（Get 时需要）")])]),t._v(" "),n("h4",{attrs:{id:"新增文档-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#新增文档-2"}},[t._v("#")]),t._v(" 新增文档")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testAddDocument")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IOException")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1. 根据 id 查询数据库中酒店数据")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Hotel")]),t._v(" hotel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" hotelService"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getById")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("61083L")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2. 将类型转换为文档类型，因为 Hotel 是对应 MySQL 数据库中数据的类，而 HotelDoc 是对应 ES 中数据的类，主要是地理坐标字段不一样")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HotelDoc")]),t._v(" hotelDoc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HotelDoc")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hotel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 3. 将 HotelDoc 转 json")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" json "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" JSON"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toJSONString")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hotelDoc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 4. 准备 Request 对象")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IndexRequest")]),t._v(" request "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IndexRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hotel"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hotelDoc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toString")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 5. 准备要新增的文档数据，也就是上面的 json")]),t._v("\n  request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("source")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("XContentType")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("JSON"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 6. 发送请求")]),t._v("\n  client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("index")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RequestOptions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DEFAULT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h4",{attrs:{id:"查询文档-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#查询文档-2"}},[t._v("#")]),t._v(" 查询文档")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testGetDocumentById")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IOException")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("GetRequest")]),t._v(" request "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("GetRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hotel"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"61082"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("GetResponse")]),t._v(" response "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RequestOptions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DEFAULT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 请求的结果是一个 JSON，其中文档放在一个 _source 属性中，所以要 getSourceAsString() 方法获取")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" json "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getSourceAsString")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将文档从 JSON 格式解析出来，也就是反序列化")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HotelDoc")]),t._v(" hotelDoc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" JSON"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("parseObject")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HotelDoc")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("println")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hotelDoc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h4",{attrs:{id:"删除文档-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#删除文档-2"}},[t._v("#")]),t._v(" 删除文档")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testDeleteDocument")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IOException")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DeleteRequest")]),t._v(" request "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DeleteRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hotel"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"61083"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RequestOptions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DEFAULT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h4",{attrs:{id:"修改文档-2"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#修改文档-2"}},[t._v("#")]),t._v(" 修改文档")]),t._v(" "),n("p",[t._v("我们上面说过，修改有两种方式：全量修改和增量修改。")]),t._v(" "),n("p",[t._v("在 RestClient 的 API 中，全量修改与新增的 API 完全一致，判断依据是 ID：")]),t._v(" "),n("ul",[n("li",[t._v("如果新增时，ID 已经存在，则是修改。")]),t._v(" "),n("li",[t._v("如果新增时，ID 不存在，则是新增。")])]),t._v(" "),n("p",[t._v("所以，这里不对全量修改进行赘述，主要说一下增量修改：")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testUpdateDocument")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IOException")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("UpdateRequest")]),t._v(" request "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("UpdateRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hotel"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"61083"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 修改的参数是每两个参数为一对 key value")]),t._v("\n  request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("doc")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"price"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"952"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"starName"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"五星"')]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("update")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RequestOptions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DEFAULT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h4",{attrs:{id:"批量导入文档"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#批量导入文档"}},[t._v("#")]),t._v(" 批量导入文档")]),t._v(" "),n("p",[t._v("如果要批量导入数据到 ES，可以利用 "),n("code",[t._v("BulkRequest")]),t._v("。"),n("code",[t._v("BulkRequest")]),t._v(" 本质就是将多个普通的 CRUD 请求组合在一起发送。其中提供了一个 "),n("code",[t._v("add()")]),t._v(" 方法，用来添加请求。")]),t._v(" "),n("div",{staticClass:"language-java extra-class"},[n("pre",{pre:!0,attrs:{class:"language-java"}},[n("code",[n("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[t._v("@Test")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("testBulkRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IOException")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 批量查询酒店数据")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),n("span",{pre:!0,attrs:{class:"token generics"}},[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Hotel")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" hotels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" hotelService"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 1.创建 Request")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BulkRequest")]),t._v(" request "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("BulkRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2.准备参数，添加多个新增的 Request")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Hotel")]),t._v(" hotel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" hotels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2.1.转换为文档类型 HotelDoc")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HotelDoc")]),t._v(" hotelDoc "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HotelDoc")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hotel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 2.2.创建新增文档的 Request 对象")]),t._v("\n    request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("add")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("IndexRequest")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hotel"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hotelDoc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("getId")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toString")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("source")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("JSON"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toJSONString")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hotelDoc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("XContentType")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("JSON"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 3.发送请求")]),t._v("\n  client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("bulk")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RequestOptions")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DEFAULT"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);