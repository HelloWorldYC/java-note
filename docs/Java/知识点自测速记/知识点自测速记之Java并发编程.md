---
title: '知识点自测速记之Java并发编程'
---

> 这篇文章以问答的形式用于快速回顾知识点以及用于自测。  
> 因为知识点相当多，即使在看时能够理解记住，但过后也往往只是有印象，大概知道是什么东西，但想回答出来却总是卡壳，看了忘，忘了看。因此，这篇文章用于帮助速记回忆，自测时可以由这些点延伸。 
> 注：参考的主要是 Guide 哥的网站内容以及 chatGPT。 



## 线程与进程

#### 什么是进程？
进程是程序的一次执行过程，是系统运行程序的基本单位，系统运行一个程序即是一个进程从创建、运行到消亡的过程。

#### 什么是线程？
线程是一个比进程更小的执行单位。一个进程可以有多个线程，不同的线程共享进程的**堆**和**方法区**资源，但每个线程都有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**。

#### 请简要描述线程与进程的关系、区别及优缺点？
一个进程可以有多个线程，多个线程共享进程的堆和方法区（JDK1.8之后是元空间）资源，但每个线程都有自己的程序计数器、虚拟机栈和本地方法栈。   
总结：线程是进程划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。

#### 程序计数器为什么是私有的？
程序计数器私有主要是为了线程切换后能恢复到正确的执行位置。   
程序计数器有两个作用：
- 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如顺序执行、选择、循环、异常处理。
- 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程切换回来的时候能够知道上次运行到哪儿了。

#### 虚拟机栈和本地方法栈为什么是私有的？
为了保证本线程中的局部变量不被其他线程访问到。   
- **虚拟机栈**：每个 Java 方法在执行之前会创建一个栈帧用于存储局部变量表、操作数栈、动态链接和方法返回地址。从方法调用直至执行完成的过程，对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。
- **本地方法栈**：和虚拟机栈所发挥的作用非常相似，区别是：虚拟机栈为虚拟机执行 Java 方法（字节码）服务，而本地方法栈为虚拟机用到的本地方法服务。

#### 一句话简单介绍堆和方法区？
堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存区域，几乎所有的对象都在堆上分配。方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

#### 并发和并行的区别？
- 并发：两个及两个以上的作业在 **同一时间段** 内执行。
- 并行：两个及两个以上的作业在 **同一时刻** 执行。

#### 同步和异步的区别？
- 同步：发出一个调用之后，在没有得到结果之前，该调用就不可以返回，一直等待。
- 异步：调用在发出之后，不用等待返回结果，该调用直接返回。

#### 为什么要使用多线程？
- 从计算机底层上来说：线程是程序执行的最小单位，线程间的切换和调度的成本远远小于进程。在单核时代，多线程主要是为了单进程利用 CPU 和 IO 的效率。而在多核时代，多个线程可以同时运行，这减少了线程上下文切换的开销，提高了进程利用多核 CPU 的能力。
- 从当代互联网的发展趋势来说：现在的系统动辄要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力和性能。

#### 使用多线程可能带来什么问题？
内存泄漏、死锁、线程不安全等。

#### 如何理解线程安全和不安全？
线程安全和不安全是在多线程环境下对于同一份数据的访问是否能够保证其正确性和一致性的描述。
- 线程安全：在多线程环境下，对于同一份数据，不管有多少个线程同时访问，都能保证这份数据的正确性和一致性。
- 线程不安全：在多线程环境下，对于同一份数据，多个线程同时访问时可能会导致数据混乱、错误或者丢失。

#### 单核 CPU 上运行多个线程效率一定会高吗？
不一定。对于单核CPU来说，同一时刻只能有一个线程在运行。如果线程是 CPU 密集型的，那么多个线程同时运行会导致频繁的上下文切换，增加了系统开销，降低了效率。如果线程是 IO 密集型的，那么多个线程同时运行能够利用 CPU 在等待 IO 时的空闲时间，提高了效率。

#### 说说线程的生命周期和状态？
这个比较有疑问，按理说应该与进程的生命周期一致，可能有一些细分。 
- NEW：初始状态，线程被创建出来但没有被调用 `start()`。
- RUNNABLE：运行状态(包括就绪 READY 和运行中 RUNNING)：线程被调用了 `start()` 等待运行的状态。
- BLOCKED：阻塞状态，需要等待锁释放。
- WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。
- TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
- TERMINATED：终止状态，表示该线程已经运行完毕。

#### 线程从 RUNNING 变为 BLOCKED以及 TIME_WAITING 状态有哪些方式？
从 RUNNING 变为 BLOCKED 主要有两种情况：
1. 等待获取锁。原因是不同线程竞争锁，比如说 `Synchronized`。
2. 在等待 IO 的时候。这个时候不是线程竞争锁，而是线程将控制权交给了底层 IO 操作系统，等待底层的 I/O 操作完成。

从 RUNNING 变为 TIME_WAITING 主要有以下五种方式：
1. `Thread.sleep(long mills)`
2. `Object.wait(long mills)`
3. `Thread.join(long mills)`
4. `LockSupport.parkNanos()`
5. `LockSupport.parkUntil()`

TIMED_WAITING 和 WAITING 状态的区别，仅仅是触发条件多了超时参数。

#### 什么是线程的上下文切换？
线程在执行过程过程中会有自己的运行条件和状态（也称上下文）。当线程发生了如下三种情况会发生线程切换，将 CPU 让出来：
- 主动让出 CPU，比如调用了 `sleep()`、`wait()` 等。
- 时间片用完。
- 调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。

线程切换意味着需要保存当前线程的上下文，等下次线程占用 CPU 的时候恢复现场。同时要加载下一个将要占用 CPU 的线程上下文。这就是线程的上下文切换。   

#### 什么是线程死锁？
线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。   
线程死锁的四个必要条件:
1. 互斥条件：该资源任意一个时刻只由一个线程占用。
2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. 循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。

#### 如何预防线程死锁？
1. 破坏请求与保持条件：一次性申请所有的资源。
2. 破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
3. 破坏循环等待条件：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。

#### 如何避免线程死锁？
在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。

#### `sleep()` 和 `wait()` 方法对比？
共同点：两者都可以暂停线程的运行。   
区别：
- `sleep()` 是 `Thread` 类的静态方法，而 `wait()` 是 `Object` 类的本地方法。
- `sleep()` 没有释放锁，而 `wait()` 方法释放了锁。
- `sleep()` 通常被用于暂停执行，而 `wait()` 通常被用于线程间交互/通信。
- `sleep()` 方法执行完成后，线程会自动苏醒，或者也可以使用 `wait(long timeout)` 超时后线程自动苏醒。`wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()` 或者 `notifyAll()` 方法。

#### 为什么 `wait()` 不定义在 Thread 中？
`wait()` 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁，并需要别的线程调用同一个对象上的 `notify()` 或者`notifyAll()` 方法唤醒。因为是与对象相关，所以定义在 `Object` 类中。

#### 为什么 `sleep()` 方法定义在 `Thread` 类中？
因为 `sleep()` 是让当前线程暂停执行，不涉及对象类，也不需要对象锁。

#### 可以直接调用 Thread 中的 `run()` 方法吗？
能够调用，但不建议。  
**调用 `start()` 方法可以启动线程并使线程进入就绪状态，直接执行 `run` 方法的话不会以多线程的方式执行。**





## JMM (Java Memory Model, Java 内存模型) 
JMM 主要定义了对于一个共享变量，当另一个线程对这个共享变量执行写操作后，这个线程对这个共享变量的可见性。

#### 为什么要弄一个 CPU 高速缓存？
CPU 高速缓存缓存的是内存数据，用于解决 CPU 处理速度和内存处理速度不对等的问题。内存缓存的是硬盘数据，用于解决硬盘访问速度过慢的问题。

#### CPU 缓存模型是怎么样的？
CPU（CPU 寄存器、L1 D-Cache、L1 I-Cache、L2 Cache）、L3 Cache、BUS 总线、Main Memory(主存)    
现代的 CPU Cache 通常分为三层，分别叫 L1、L2、L3 Cache。

#### CPU Cache 的工作方式？
CPU Cache 的工作方式：先复制一份数据到 CPU Cache 中，当 CPU 需要用到的时候就可以直接从 CPU Cache 中读取数据，当运算完成后，再将运算得到的数据写回 Main Memory 中。但是，这样存在内存缓存不一致性的问题！假设两个线程从 CPU Cache 中读取的 `i=1`，两个线程做了 `i++` 运算后再写回 Main Memory 之后 `i=2`，而正确结果应该是 `i=3`。   

CPU 为了解决内存缓存不一致性问题可以通过制定缓存一致性协议（比如 MESI 协议）或者其他手段解决。这个缓存一致性协议指的是在 CPU 高速缓存与主内存交互的时候需要遵守的原则和规范。   
操作系统通过 **内存模型** 定义一系列规范来解决这个问题。

#### 什么是指令重排序？
简单的说，就是系统在执行代码的时候并不一定是按照写的代码的顺序依次执行的。  

#### 指令重排序有哪几种？
- **编译器优化重排**：编译器在不改变单线程程序语义的前提下，重新安排语句的执行顺序。
- **指令并行重排**：现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

此外，内存系统也会有重排序，但不是真正意义上的重排序，在 JMM 里表现为主存和本地内存的内容可能不一致，进而导致程序在多线程下执行可能出现问题。  
Java 源代码会经历 **编译器优化重排 -> 指令并行重排 -> 内存系统重排** 的过程，最终才变成操作系统可执行的指令序列。  

#### 指令重排序有什么隐患？怎么解决？
**指令重排序可以保证串行语义一致，但没有义务保证多线程间的语义也一致**，所以在多线程下，指令重排序可能会导致一些问题。   
- 对于编译器重排序：通过禁止特定类型的编译器重排序来禁止重排序。
- 对于处理器重排序（指令并行重排和内存系统重排）：通过插入内存屏障来禁止特定类型的处理器重排序。

#### 什么是 JMM？
JMM 其实是 Java 定义的并发编程的规范，抽象了线程和主内存的关系，以及规定了从 Java 源代码到 CPU 可执行指令的转化需要遵守哪些和并发相关的原则和规范。   

#### 为什么需要 JMM？
因为并发编程下，像 CPU 多级缓存和指令重排这类设计可能会导致程序运行出现一些问题。

#### JMM 是如何抽象线程和主内存之间的关系的？
线程之间的共享变量必须存储在主内存中。   
在当前 Java 内存模型下，线程从主存拷贝变量到本地内存中，在本地内存中进行修改。这可能会导致数据的不一致性，因此 JMM 定义了八种同步操作来规避这个问题。   
八种同步操作：**锁定**、**解锁**、**读取**、**载入**、**使用**、**赋值**、**存储**、**写入**。

#### 什么是主内存？什么是本地内存？
- 主内存：所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量还是局部变量。（个人理解应该就是堆中的对象）
- 本地内存：每个线程都有一个私有的本地内存来存储共享变量的副本，并且每个线程只能访问自己的本地内存，无法访问其他线程的本地内存。

#### Java 内存区域和 JMM 有什么区别？
- Java 内存区域是和 Java 虚拟机的运行时区域相关，定义了 JVM 在运行时如何分区存储程序数据。
- JMM 时和 Java 并发编程相关的，可以看作是一组规范，目的是简化多线程编程，增强程序可移植性的。

#### 什么是 happens-before 原则？
在分布式环境中，通过一系列规则来定义逻辑时钟的变化，从而能通过逻辑时钟来对分布式系统中的事件的先后顺序进行判断。逻辑时钟并不度量时间本身，仅区分事件发生的前后顺序，其本质就是定义了一种 happens-before 关系。   
**happens-before 表达的意义不仅是一个操作发生在另一个操作前面，它更想表达的是前一个操作的结果对于后一个操作是可见的，无论这两个操作是否是同一个线程内的。**

#### 为什么需要 happens-before 原则？
为了程序员和编译器、处理器之间的平衡。
- 为了对编译器和处理器的约束尽可能少，只要不改变程序的执行结果，编译器和处理器怎么进行重排序优化都行。
- 对于会改变程序执行结果的重排序，JMM 要求编译器和处理器必须禁止这种重排序。

#### happens-before 常见规则有哪些？
有8条，着重了解下面5条：
- **程序顺序规则**：一个线程内，按照代码顺序，写在前面的操作 happens-before 写在后面的操作。
- **解锁规则**：加锁 happens-before 解锁。
- **volatile 变量规则**：对一个 volatile 变量的写操作 happens-before 后面对这个 volatile 变量的读操作。
- **传递规则**：如果 A happens-before B，B happens-before C，那么 A happens-before C。
- **线程启动规则**：Thread 对象的 `start()` 方法 happens-before 于这个线程的每一个动作。

#### happens-before 和 JMM 有什么关系？
happens-before 是 JMM 中的一个关键概念，JMM 呈现给程序员的视图就是 happens-before 规则。

#### 并发编程的三个重要特性？
- 原子性：要么全部执行，要么都不执行。Java 中可以借助 `Synchronized` 和各种 `Lock` 以及各种原子类实现原子性。
- 可见性：当一个线程对共享变量进行了修改，另外的线程立即可以看到修改后的最新值。在 Java 中，可以借助 `Synchronized`、`volatile` 以及各种 `Lock` 实现可见性。
- 有序性：指令重排序可以保证串行语义一致，但是没有义务保证多线程间的语义也一致。在 Java 中，`volatile` 关键字可以禁止指令进行重排序。




## Volatile 关键字

#### 如何保证变量的可见性？
如果我们将变量声明为 `volatile`，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。

#### 如何禁止指令重排序？
`volatile` 关键字除了可以保证变量的可见性，还有一个重要作用就是防止 JVM 的指令重排序。   
如果将变量声明为 `volatile`，那么在对这个变量进行读写操作的时候，会通过插入特定的 **内存屏障** 的方式来禁止指令重排序。

#### volatile 能保证原子性吗？
不能保证。



## 乐观锁和悲观锁

#### 什么是悲观锁？悲观锁的应用场景是什么？
悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题，所以在获取资源操作的时候都会上锁，其他线程想拿到这个资源就会阻塞直到锁被释放。即，共享资源每次只给一个线程使用，其他线程阻塞，用完后再把资源转让给其他线程。   
`Synchronized` 和 `ReentrantLock` 等独占锁就是悲观锁思想的实现。   
悲观锁通常多用于写比较多的情况，这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。

#### 什么是乐观锁？乐观锁适用于什么场景？
乐观锁总是假设最好的情况，认为共享资源每次被访问不会出现问题，线程可以不停执行，无需加锁无需等待，只是在提交修改的时候去验证对应的资源是否被其他线程修改了（具体的方法可以使用版本号或 CAS 算法）。  
乐观锁通常用于写比较少或者说读比较多的情况，这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量。

#### 如何实现乐观锁？
- 版本号
- CAS 算法，用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。它是一个原子操作，底层依赖于一条 CPU 的原子指令。涉及三个操作数：
  - **V**：要更新的变量值（Var）
  - **E**：预期值（Expected）
  - **N**：更新后的值（NEw）

#### 乐观锁存在哪些问题？
- ABA 问题：两次读取中间修改过，但 CAS 认为它是没修改过的。（加版本号或时间戳解决）
- 循环时间长开销大：CAS 通过自旋来进行重试，不成功就会一直循环，这样给 CPU 带来非常大的执行开销。（若 JVM 能支持处理器提供的 `pause` 指令则有用）
- 只能保证一个共享变量的原子操作（使用锁或者利用 `AtomicReference` 类把多个共享变量合并成一个共享变量来操作）



## Synchronized 关键字

#### Synchronized 是什么？有什么用？
`Synchronized` 是同步的意思，Java 中用于并发编程的关键字，主要解决的是多个线程之间访问资源的同步性，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。    
`Synchronized` 属于**重量级悲观锁**，但 Java6 引入了大量的优化，例如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。JDK 源码和很多框架都大量使用了 `Synchronized`。

#### 如何使用 Synchronized？
- 修饰实例方法（锁当前对象实例）
- 修饰静态方法（锁当前类）
- 修饰代码块（对指定对象/类加锁）

#### 构造方法可以用 Synchronized 方法修饰吗？
**构造方法不能使用 `Synchronized` 关键字修饰**。因为构造方法本身是在对象创建的时候使用的，本身就属于线程安全的，不存在同步的构造方法一说。

#### Synchronized 底层原理了解吗？
`Synchronized` 同步 **语句块（代码块）** 的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指向同步代码块的结束位置。

当执行 `monitorenter` 指令时，线程试图获取锁也就是获取对象监视器 `monitor` (每个对象都有)的持有权，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1。对象锁的拥有者线程才可以执行 `monitorexit` 指令来释放锁，执行之后将锁计数器设为 0，表明锁被释放，其他线程可以尝试获取锁。    

`Synchronized` 修饰的 **方法** 则没有 `monitorenter` 和 `monitorexit` 指令，取而代之的是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。   

不过不管是修饰语句块还是修饰方法，本质上都是对对象监视器 `monitor` 的获取。

#### JDK1.6 之后的 Synchronized 方法底层做了哪些优化？
JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术，来减少锁操作的开销。  

锁主要存在四种状态，依次是：**无锁状态**、**偏向锁状态**、**轻量级锁状态**、**重量级锁状态**，它们会随着竞争的激烈而升级。**注意锁可以升级，但不能降级**，这种策略是为了提高获得锁和释放锁的效率。

#### 为什么锁能够升级却不能降级？
在一般情况下，锁的升级是相对容易的，因为高级别的锁通常包含了低级别锁的信息。例如，类级别的锁可能包含对象级别锁的信息。因此，当升级时，只需保留高级别锁即可。   

然而，锁的降级却相对困难，因为在降级时需要确保释放的是高级别锁，而不是低级别锁。如果直接释放高级别锁，可能会导致并发问题，因为其他线程可能已经获取了低级别锁。  

另外，锁的降级可能引入新的竞争条件，因为在降级时需要在低级别锁被获取之前释放高级别锁，这可能导致其他线程竞争低级别锁。  

#### Synchronized 和 volatile 有什么区别？
它们两个是互补的存在，而不是对立的。
- `volatile` 只能用于变量，而 `Synchronized` 则可以修饰方法和代码块。
- `volatile` 是线程同步的轻量级实现，性能肯定比 `synchronized` 要好。
- `volatile` 主要用于解决变量在多个线程之间的可见性，而 `synchronized` 解决的是多个线程之间访问资源的同步性。



## ReentrantLock

#### ReentrantLock 是什么？
`ReentrantLock` 实现了 `Lock` 接口，是一个可重入且独占式的锁，和 `synchronized` 类似，但它更加灵活、强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。   

`ReentrantLock` 里面有一个内部类 `Sync`，`Sync` 继承 AQS(`AbstractQueuedSynchronizer`)，添加锁和和释放锁的大部分操作基本都是在 `Sync` 中实现的，`Sync` 有公平锁 `FairSync` 和非公平锁 `NonfairSync` 两个子类。`ReentrantLock` 默认使用非公平锁。

#### 公平锁和非公平锁有什么区别？
- 公平锁：锁被释放后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。
- 非公平锁：锁被释放之后，后申请的线程可能会先获取到锁，是随机或按其他优先级排序的。性能更好，但可能会导致某些线程一直获取不到锁。

#### Synchronized 和 ReentrantLock 有什么区别？
- `Synchronized` 和 `ReentrantLock` 都是可重入锁，即线程可以再次获取自己的内部锁（不可重入锁的话可能造成死锁）。JDK 提供的所有现成的 `Lock` 实现类，包括 `Synchronized` 关键字都是可重入的。
- `Synchronized` 依赖于 JVM，而 `ReentrantLock` 依赖于 JDK（也就是 API 层面，需要 `lock()` 和 `unlock()` 方法配合 try/finally 语句块来完成）。
- `ReentrantLock` 比 `Synchronized` 增加了一些高级功能，主要有三点：
  - 等待可中断
  - 可实现公平锁
  - 可实现选择性通知（锁可以绑定多个条件 `Condition`，通过 `signalAll()` 唤醒注册在该 `Condition` 实例上等待的线程）

#### 可中断锁和不可中断锁有什么区别？
- **可中断锁**：获取锁的过程中可以被中断，不需要一直等到获取锁之后才能进行其他逻辑处理。
- **不可中断锁**：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。`Synchronized` 就属于不可中断锁。



## ReentrantReadWriteLock

#### 什么是 ReentrantReadWriteLock？
`ReentrantReadWriteLock` 实现了 `ReadWriteLock`，是一个可重入的读写锁，既可以保证多个线程同时读的效率，又可以保证有写入操作时的线程安全。   
- 一般锁进行并发控制的规则：读读互斥、读写互斥、写写互斥。
- 读写锁进行并发控制的规则：读读不互斥、读写互斥、写写互斥。   

`ReentrantReadWriteLock` 其实是两把锁，一把是 `WriteLick`，一把是 `ReadLock`。读锁是共享锁，写锁是独占锁。   
`ReentrantReadWriteLock` 底层也是基于 AQS 实现的，也有公平锁和非公平锁，默认是非公平锁。

#### ReentrantReadWriteLock 适用于什么场景？
适合在读多写少的情况下使用。

#### 共享锁和独占锁有什么区别？
- 共享锁：一把锁可以同时被多个线程占有。
- 独占锁：一把锁只能被一个线程占有。

#### ReentrantReadWriteLock：线程获取读锁还能获取写锁吗？
- 在线程持有读锁的情况下，不能取得写锁，不管读锁是不是当前线程占有的。（因为在有读锁的情况下，可能有其他线程也在读，所以不能写）
- 在线程持有写锁的情况下，可以继续获取读锁。（写锁是独占锁，说明没有其他线程在使用，所以可以获取读锁）

#### 读锁为什么不能升级为写锁？
**写锁可以降级为读锁，但读锁不能升级为写锁。**因为读锁升级为写锁会引起线程的争夺，毕竟写锁是独占锁。而且，还有可能会发生死锁问题，AB都想升级为写锁，都在等着对方释放资源。




## StampedLock

#### 什么是 StampedLock？
`StampedLock` 是 JDK1.8 引入的性能更好的读写锁，**不可重入**且不支持条件变量 `Condition`。   
不同于一般的 `Lock` 类，`StampedLock` 并不是直接实现 `Lock` 或 `ReadWriteLock` 接口，而是基于 **CLH** 锁独立实现的。（AQS 也是基于 CLH）  

`StampedLock` 提供了三种模式的读写控制：（在一定条件下可以相互转换）
- **写锁**：独占锁，类似于 `ReentrantReadWriteLock` 的写锁，不过不可重入。
- **读锁**：共享锁，类似于 `ReentrantReadWriteLock` 的读锁，不过不可重入。
- **乐观读**：允许多个线程获取了乐观读以及读锁，同时允许一个线程获取写锁。  

#### 为什么 StampedLock 不可重入？
`StampedLock` 获取锁的时候会返回一个 `long` 类型的数据戳，该数据戳用于稍后的锁释放参数，如果返回的数据戳为 0，则表示锁获取失败。当前线程持有了锁再次获取的话还是会返回一个新的数据戳，所以这是不可重入的。

#### StampedLock 为什么性能更好？
因为多了一个 **乐观读** 的模式，可以允许一个写线程同时获取写锁，不会导致所有的写线程阻塞。

#### StampedLock 适用于什么场景？
适合于 **读多写少** 的场景。

#### StampedLock 的底层原理了解吗？
`StampedLock` 不是直接实现 `Lock` 或 `ReadWriteLock` 接口，而是基于 **CLH 锁** 实现的（AQS 也是基于 CLH），CLH 锁是对自旋锁的一种改良，是一种隐式的链表队列。`StampedLock` 通过 CLH 队列进行线程的管理，通过同步状态值 `state` 来表示锁的状态和类型。




## Atomic 原子类



## ThreadLocal 类

#### ThreadLocal 有什么用？
存储每个线程的私有数据。如果创建了一个 `ThreadLocal` 变量，则访问这个变量的每个线程都会有这个变量的本地副本，从而避免了线程安全问题。

#### ThreadLocal 原理了解吗？
`ThreadLocal` 是通过 `ThreadLocalMap` 进行存储的，每个 `Thread` 中都具备一个 `ThreadLocalMap`，而 `ThreadLocalMap` 可以存储以 `ThreadLocal` 为 key，`Object` 对象为 value 的键值对。   
注意：最终的变量是放在了当前线程的 `ThreadLocalMap` 中，并不是存在 `ThreadLocal` 上，`ThreadLocal` 可以理解为是 `ThreadLocalMap` 的封装，传递了变量值。

#### ThreadLocal 内存泄漏是怎么导致的？
`ThreadLocalMap` 中使用的 key 是弱引用，而 value 是强引用。那么如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收时，key 会被清理掉，而 value 则不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry，而且不会被 GC 回收，这个时候就会产生内存泄漏。  

`ThreadLocalMap` 实现中考虑到了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。




## 线程池

#### 什么是线程池？
线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理之后线程并不会立即被销毁，而是放回线程池中等待下一个任务。

#### 为什么要使用线程池？
线程池就是利用了池化技术，而池化技术的思想时为了减少每次获取资源的消耗，提高对资源的利用率。  
- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

#### 如何创建线程池？
- 通过 `ThreadPoolExecutor` 构造函数来创建（推荐）
- 通过 `Executor` 框架的工具类 `Executors` 来创建。

可以创建多种类型的线程池：
- `FixedThreadPool`：固定线程数量的线程池。
- `SingleThreadExecutor`：只有一个线程的线程池。
- `CachedThreadPool`：可根据实际情况调整线程数量的线程池。
- `ScheduledThreadPool`：用来在给定的延迟后运行任务或者定期执行任务的线程池。

#### 为什么不推荐使用内置线程池？
- `FixedThreadPool` 和 `SingleThreadExecutor`：使用的是无界的 `LinkedBlockingQueue`，任务队列的最大长度为 `Integer.MAX_VALUE`，可能堆积大量的请求，从而导致 OOM。
- `CachedThreadPool`：使用的是同步队列 `SynchronousQueue`，允许创建的线程数量为 `Integer.MAX_VALUE`，如果任务数量过多且执行速度较慢，可能会创建大量的线程，从而导致 OOM。
- `ScheduledThreadPool` 和 `SingleThreadSCheduledExecutor`：使用的是无界的延迟阻塞队列 `DelayedWorkQueue`，任务队列最大长度为 `Integer.MAX_VALUE`，可能会堆积大量的请求，从而导致 OOM。

#### 线程池常用参数有哪些？
`ThreadPoolExecutor` 3 个最重要的参数：
- `corePoolSize`：核心线程数，任务队列未达到队列容量时，最大可以同时运行的线程数量。
- `maximumPoolSize`：最大线程数量。任务队列存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- `WorkQueue`：新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到，新任务会存放在队列中等待执行。

其他常见的参数：
- `keepAliveTime`：线程池中超过核心线程数的线程在没有任务执行之后，会在 `keepAliveTime` 之后被回收销毁。
- `unit`：`keepAliveTime` 的时间单位。
- `threadFactory`：`executor` 创建新线程的时候通过这个工厂来创建。
- `handler`：饱和策略。当前同时运行的线程数达到最大线程数并且队列也满的时候，执行的策略。

#### 线程池的饱和策略有哪些？
- `ThreadPoolExecutor.AbortPolicy`：抛出 `RejectedExecutionException` 来拒绝新任务的处理。
- `ThreadPoolExecutor.CallerRunsPolicy`：将任务会退给调用者，使用调用者的线程来执行任务。
- `ThreadPoolExecutor.DiscardPolicy`：不处理新任务，直接丢弃掉。
- `ThreadPoolExecutor.DiscardOldestPolicy`：此策略将丢弃最早未处理的任务请求。

#### 线程池常用的阻塞队列有哪些？
- `LinkedBlockingQueue(无界队列)`：`FixedThreadPool` 和 `SingleThreadExecutor`。队列无界，所以 `FixedThreadPool` 最多只能创建核心线程数的线程。
- `SynchronousQueue(同步队列)`：`CachedThreadPool`。队列没有容量，不存储元素。`CachedThreadPool` 线程数可以扩展，可能会创建大量线程，从而导致 OOM。
- `DelayedWorkQueue(延迟阻塞队列)`：`ScheduledThreadPool` 和 `SingleThreadScheduledExecutor`。队列会自动扩容，即永远不会阻塞，最多也只能创建核心线程数的线程。

#### 线程池处理任务的流程了解吗？
1. 如果当前线程数小于核心线程数，新建线程来执行任务。
2. 如果当前线程数等于大于核心线程数，但小于最大线程数，把任务放在任务队列中等待执行。
3. 如果任务队列满了，但是当前线程数小于最大线程数，就新建线程执行任务。
4. 如果当前线程数达到最大线程数，且任务队列也满了，由饱和策略决定。

#### 如何给线程池命名？
通常有以下两种方式：
1. 利用 guava 的 `ThreadFactoryBuilder`。
2. 自己实现 `ThreadFactory`。

#### 如何设定线程池的大小？
- 对于 **CPU 密集型任务**，可以设置为 N + 1，其中 N 为 CPU 核心数。多出来的 1 是为了防止线程偶发的缺页中断，或者其他原因导致的任务暂停而带来的影响。
- 对于 **IO 密集型 任务**，可以设置为 2N。

线程数更严谨的计算的方法应该是：`最佳线程数 = N（CPU 核心数）∗（1+WT（线程等待时间）/ST（线程计算时间））`，其中 `WT（线程等待时间）=线程运行总时间 - ST（线程计算时间）`。

#### 如何动态修改线程池的参数？
可以参考美团技术团队的思路：主要对线程池的3个核心参数实现自定义可配置。


## Future

#### Future 类有什么作用？
`Future` 类是异步思想的典型运用，将耗时任务交给子线程去执行，自己则继续执行其他操作，等子线程执行完成后，再通过 `Future` 类获取执行的结果，避免程序一直原地等待耗时任务完成导致执行效率太低。   
这其实就是多线程中经典的 `Future 模式`。

`Future` 类时一个接口，主要定义了 5 个方法 4 个功能：
- 取消任务。
- 判断任务是否被取消。
- 判断任务是否执行完成。
- 获取任务执行结果。

#### Callable 和 Future 有什么关系？
`Callable` 和 `Future` 都是接口，分别用于实现多线程的任务执行和获取任务执行结果。   

`Callable` 主要还是与 `Runnable` 进行区分。`Callable` 类似于 Runnable 接口，但有一个关键的区别：`Callable` 的 `call` 方法可以返回一个值，并且可以抛出异常。而 `Runnable` 接口则没有返回值。   

`Future` 的一个实现 `FutureTask` 相当于对 `Callable` 进行了封装，管理着任务执行的情况，存储了 `Callable` 的 `call` 方法的执行结果。`FutureTask` 有两个构造函数，可以传入 `Callable` 和 `Runnable` 对象，但实际上，传入 `Runnable` 对象也会在方法内部转化为 `Callable` 对象。

#### CompletableFuture 类有什么作用？
`Future` 在实际使用过程中存在一些局限性，比如不支持异步任务的编排组合、获取计算结果的 `get()` 方法为阻塞调用。   
`CompletableFuture` 类则解决了这些缺陷。`CompletableFuture` 除了提供更为好用和强大的 `Future` 特性之外，还提供了函数式编程、异步任务编排组合（可以将多个异步任务串联起来，组成一个完整的链式调用）等能力，这是由 `CompletionStage` 接口提供的。


## AQS

#### AQS 是什么？
AQS，全称为 `AbstractQueuedSynchronizer`，抽象队列同步器。这个类位于 `java.util.concurrent.locks` 包下面。  
AQS 是一个抽象类，主要用来构建锁和同步器，它提供了一些通用功能的实现，因此使用它可以简单高效地构造出应用广泛的同步器，比如 `ReentrantLock` 和 `ReentrantReadWriteLock`。

#### AQS 的原理是什么？
AQS 核心思想是，如果被请求的共享资源空闲，则将请求资源的线程设置为有效工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 **CLH 队列锁** 实现的，即 将暂时获取不到锁的线程加入到队列中。    

CLH 队列是一个虚拟的双向队列（即不存在队列实例，仅存在节点之间的关联关系）。AQS 是将每个请求共享资源的线程封装成一个节点来实现锁的分配。在 CLH 同步队列中，一个节点表示一个线程，它保存着线程的引用、当前节点在队列中的状态、前驱节点、后继节点。   

以 `ReentrantLock` 为例，`state` 初始值为 0，表示未锁定状态。A 线程 `lock()` 时，会调用 `tryAcquire()` 独占该锁并将 `state+1` 。此后，其他线程再 `tryAcquire()` 时就会失败，直到 A 线程 `unlock()` 到 `state=0`（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（`state` 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多少次，这样才能保证 `state` 是能回到零态的。

#### Semaphore 有什么用？
`Semaphore` 信号量，只有特定数量的线程可以同时访问资源。当初始的资源个数为 1 时，`Semaphore` 退化为排他锁。   
`Semaphore` 有两种模式：
- 公平模式：调用 `acquire()` 方法的顺序就是获取许可证的顺序，遵循 FIFO。 
- 非公平模式：抢占式的。

#### Semaphore 的原理是什么？
`Semaphore` 是共享锁的一种实现，它默认构造 AQS 的 `state` 值为 `permits`，也就是许可证的数量，线程只有拿到许可证才能执行。   
线程通过 `acquire()` 方法获取许可证。如果 `state>=0` 的话，则表示可以获取成功。如果获取成功的话，使用 CAS 操作去修改 `state` 的值 `state=state-1`。如果 `state<0` 的话，则表示许可证数量不足。此时会创建一个 Node 节点加入阻塞队列，挂起当前线程。   
线程通过 `release()` 方法尝试释放许可证，并使用 CAS 操作去修改 `state` 的值 `state=state+1`。释放许可证成功之后，同时会唤醒同步队列中的一个线程。被唤醒的线程会重新尝试去修改 `state` 的值 `state=state-1` ，如果 `state>=0` 则获取令牌成功，否则重新进入阻塞队列，挂起线程。

#### CountDownLatch 有什么用？
`CountDownLatch` 允许 `count` 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。   
`CountDownLatch` 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 `CountDownLatch` 使用完毕后，它不能再次被使用。

#### CountDownLatch 的原理是什么？
`CountDownLatch` 是共享锁的一种实现,它默认构造 AQS 的 `state` 值为 `count`。当线程使用 `countDown()` 方法时,其实使用了 `tryReleaseShared()` 方法以 CAS 的操作来减少 `state`,直至 `state` 为 0 。当调用 `await()` 方法的时候，如果 `state` 不为 0，那就证明任务还没有执行完毕，`await()` 方法就会一直阻塞，也就是说 `await()` 方法之后的语句不会被执行。直到 `count` 个线程调用了 `countDown()` 使 `state` 值被减为0，或者调用 `await()` 的线程被中断，该线程才会从阻塞中被唤醒，`await()` 方法之后的语句得到执行。

#### 用过 CountDownLatch 吗？什么场景下使用的？
还未使用过。

#### CyclicBarrier 有什么用？
`CyclicBarrier` ，即可循环使用屏障。它要做的事情是：让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。  

`CyclicBarrier` 和 `CountDownLatch` 类似，都是实现线程间的技术等待。但 `CountDownLatch` 是基于 AQS 的，而 `CyclicBarrier` 则是基于 `ReentrantLock` 和 `Condition` 的，功能更为强大。注意，`ReentrantLock` 也是基于 AQS 的。

#### CyclicBarrier 的原理是什么？
`CyclicBarrier` 内部通过一个 `count` 变量作为计数器，`count` 的初始值为 `parties` 属性的初始化值，每当一个线程到了栅栏这里了，那么就将计数器减 1。如果 `count` 值为 0 了，表示这是这一代最后一个线程到达栅栏，就尝试执行我们构造方法中输入的任务。在拦截过程中，每个线程调用 `await()` 方法告诉 `CyclicBarrier` 我已经到达了屏障，然后当前线程被阻塞。
