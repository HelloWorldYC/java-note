---
title: '知识点自测速记之Redis'
---

> 这篇文章以问答的形式用于快速回顾知识点以及用于自测。  
> 因为知识点相当多，即使在看时能够理解记住，但过后也往往只是有印象，大概知道是什么东西，但想回答出来却总是卡壳，看了忘，忘了看。因此，这篇文章用于帮助速记回忆，自测时可以由这些点延伸。  


## Redis 基础

#### Redis 是什么？
Redis 是一个基于 C 语言开发的开源的非关系型数据库。Redis 的数据是保存在内存中的，因此读写速度非常快。并且，Redis 存储的是 KV 键值对数据。

#### Redis 为什么快？
1. Redis 基于内存，内存的访问速度是磁盘的上千倍。
2. Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用。
3. Redis 内置了多种优化过后的数据类型/结构实现，性能非常高。

#### 分布式缓存常见的技术选型有哪些？
Memcached 和 Redis，以及 Tendis。

#### 说一下 Redis 和 Memcached 区别和共同点？
共同点：
1. 都是基于内存的数据库，一般都用来当作缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

区别：
1. Redis 支持**更丰富的数据类型**（支持更复杂的应用场景）。Memcached 支持最简单的 k/v 数据类型，而 Redis 不仅支持 k/v，还提供 list、set、zset、Hash 等数据结构的存储。
2. Redis 支持**数据的持久化**，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 把数据全部存在内存中。
3. Redis 有**灾难恢复机制**。因为可以持久化。
4. Redis 在服务器内存使用完后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完后，就会直接报异常。
5. Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。但是 Redis 目前是**原生支持集群模式**的。
6. Memcached 是多线程，非阻塞 IO 复用的网络模型；**Redis 使用单线程的多路 IO 复用模型**。
7. Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。
8. Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了**惰性删除与定期删除**。

#### 为什么要用 Redis？（为什么要用缓存？）
- **高性能**：Redis 是基于内存的，操作数据相当快。
- **高并发**：使用 Redis 作为缓存，能够使得系统的 QPS 大大提高，即提高了系统整体的并发。

#### 常见的缓存策略有哪些？
- 旁路缓存（Cache Aside Pattern）
- 读写穿透（Read/Write Through Pattern）
- 异步缓存写入（Write Behind Pattern）

#### 旁路缓存策略是怎么样的？读写步骤？
旁路缓存时平时使用较多的一个缓存读写模式，比较适合读请求比较多的场景。   
- 读：从缓存中读取数据，读取到就直接返回应用。缓存中读取不到，就从数据库中读取数据返回应用。应用再把读到的数据放到缓存中。
- 写：先更新数据库，再直接删除缓存。

#### 旁路缓存在更新数据的时候，可以先删除缓存，再更新数据库吗？
不行，因为可能造成**数据库和缓存数据不一致**，以及数据更新期间，可能有大量请求无法得到处理导致数据库宕机。    
数据库和缓存数据不一致例子： 请求 1 把缓存中的 A 数据删除 -> 请求 2 从数据库读取数据 -> 请求 1 再把数据库中 A 数据更新。

#### 旁路缓存在更新数据的时候，若是先更新数据库，再删除缓存呢？
理论上可能还是会出现数据不一致性问题，但概率非常小，因为缓存的写入速度比数据库写入速度快很多。

#### 旁路缓存的缺陷？
1. **首次请求数据一定不在缓存中**：预热，提前将热点数据放入缓存中。
2. **写操作比较频繁的话导致缓存中的数据会被频繁删除，这样会影响缓存命中率**：
  - 数据库和缓存数据强一致场景：更新数据库的时候同样更新缓存，不过我们需要加一个锁/分布式锁来保证更新缓存的时候不存在线程安全问题。
  - 可以短暂地允许数据库和缓存数据不一致的场景：更新数据库的时候同样更新缓存，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。

#### 读写穿透模式进行缓存是怎样的？读写步骤？
读写穿透模式服务端将缓存视为主要数据存储，简单理解就是将缓存作为中间人，读写都必须通过缓存。   
- 读：先从缓存中读取数据，读取到就返回应用。缓存中读取不到，就从数据库加载数据到缓存中，再从缓存返回数据给应用。
- 写：先查缓存存不存在数据，缓存中不存在的话就直接更新数据库。若缓存存在，则先更新缓存数据，再由缓存服务去更新数据库。

#### 旁路缓存和读写穿透模式是有什么联系和区别？
读写穿透实际只是在旁路缓存之上进行了封装。在旁路缓存下，发生读请求的时候，如果缓存中不存在对应的数据，是由客户端自己负责把数据写入缓存，而读写穿透模式则是先读取到缓存再返回，这对客户端是透明的。

和旁路缓存一样，读写穿透模式也有首次请求数据一定不在缓存的问题，对于热点数据可以提前放入缓存中。

#### 异步缓存写入模式是什么样的？它与读写穿透模式又有哪些区别？
异步缓存写入和读写穿透模式很相似，两者都是由缓存服务来负责缓存和数据库的读写。   
但是，两个又有很大的不同：读写穿透模式是同步更新缓存和数据库，而读写穿透模式则是只更新缓存，不直接更新数据库，而是改为异步批量的方式来更新数据库。



## Redis 应用

#### Redis 除了做缓存，还可以做什么？
- **分布式锁**：通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 Redisson 来实现分布式锁。
- **限流**：一般都是通过 Redis + Lua 脚本的方式来实现限流。
- **消息队列**：Redis 自带的 List 以及 Redis5.0 中增加的 Stream 可以用来做消息队列。
- **延时队列**：Redisson 内置了延时队列（基于 Sorted Set 实现的）。
- **分布式 Session**：利用 String 或者 Hash 保存 Session，所有的服务器都可以访问。
- **复杂的业务场景**：利用 Bitmap 统计活跃用户、利用 Sorted Set 维护排行榜。

#### 如何基于 Redis 实现简单的分布式锁？
不论是本地锁还是分布式锁，核心都在于 **互斥**。   
在 Redis 中，`SETNX` 命令可以帮助实现互斥。`SETNX` 即 `set if not exits` （对应 Java 中的 `setIfAbsent` 方法），key 不存在才会设置值，若 key 存在则什么都不做。   
释放锁时，直接通过 `DEL` 命令删除对应的 key 即可。为了保证锁释放操作的原子性，建议使用 Lua 脚本来执行。    

这种方式在一些情况下可能会导致锁无法释放，因此可以给锁（也就是 key）设置过期时间。一定要保证设置指定的 key 的值和过期时间是一个原子操作，否则仍有可能会出现锁无法释放的问题。此外，这种解决方法仍存在漏洞：如果操作共享资源的时间大于过期时间，就会出现锁提前过期的问题，进而导致分布式锁直接失效。如果过期时间设置太长，又会影响到性能。可以采用 Redisson 的 Watch Dog （看门狗）实现锁的优雅续期，也就是操作共享资源的操作还未完成，锁过期时间能够自动续期。

#### Redis 如何作消息队列？
Redis2.0 前只能通过 List 来实现。这种方式缺陷巨大，像消息确认机制等功能需要手动实现，最要命的是没有广播机制，消息也只能被消费一次。     
Redis2.0 引入了发布订阅功能，基于 channel 来实现消息发布和订阅，解决了 List 实现消息队列没有广播机制的问题。不过，还存在消息丢失、消息堆积问题。   
为此，Redis5.0 新增加了 Stream 数据结构来做消息队列。但是 Stream 使用麻烦，且仍有问题不太好解决比如在 Redis 发生故障恢复后不能保证消息至少被消费一次。    
总的来说，Redis 做消息队列还是有很多欠缺的地方，建议用 RocketMQ、Kafka 等。





## Redis 数据结构

#### 有哪 5 种基本数据结构？它们的底层实现是哪 8 种数据结构？
- String：SDS（简单动态字符串）
- List：LinkedList（双向链表）、ZipList（压缩列表）、QuickList（快速列表，LinkedList 和 ZipList 的结合）
- Set：Dict（哈希表/字典）、Intset（整数集合）
- Zset：ZipList（压缩列表）、SkipList（跳跃表）
- Hash：Dict（哈希表/字典）、ZipList（压缩列表）

#### Hash 是怎样的？
Redis 中的 Hash 是一个 String 类型的 field-value（键值对） 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接修改这个对象中的某些字段的值。    
Hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 Hash 做了更多优化。

#### Redis 中的 Set 有什么特点？
Redis 中的 Set 有点类似于 Java 中的 HashSet，集合中元素无序不可重复。   
Redis 中的 Set 实现了交集、并集、差集的操作，这样的话，Set 可以非常方便的实现共同关注、共同粉丝、共同喜欢等功能。

#### Sorted Set 是怎么排序的？
Sorted Set 相比于 Set 增加了一个权重参数 `score`，使得集合中的元素能够按 `score` 进行有序排列，还可以通过 `score` 的范围来获取元素的列表。

#### 有哪 3 种特殊结构？
- Bitmap（位图）
- HyperLogLog（基数统计）
- Geospatial（地理位置）

#### Bitmap 是怎么存储的？
Bitmap 存储的是连续的二进制数字（0 和 1），通过 Bitmap，只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身。可以将 Bitmap 看作是一个存储二进制数字（0 和 1）的数组，数组中每个元素的下标叫做 offset（偏移量）。

#### HyperLogLog 的底层实现原理？
HyperLogLog 是一种有名的基数计数概率算法，Redis 提供的 HyperLogLog 占用空间非常非常小，只需要 12k 的空间就能存储接近 2^64 个不同元素。并且，Redis 对 HyperLogLog 的存储结构做了优化，采用两种方式计数：
- 稀疏矩阵：计数较少的时候，占用空间很小。
- 稠密矩阵：计数达到某个阈值的时候，占用 12k 的空间。

Redis 中设有 2^14 = 16384 个桶，每个桶有 6 位，能表示的最大数字是 63，二进制为 `111 111`。   
在元素存入时，value 会被哈希成 64 位，前 14 位用于分桶，二进制转为十进制就是桶标号。后 50 位中，出现 1 的位置索引 `index` 转成二进制，与对应桶中的数字进行比较，若 `index` 较大，则设置桶的值为 `index`，否则不变。   
由于每个桶都设置了 value，每个桶都有一个 `k_max`，将所有桶的 `k_max` 相加就是这个 HyperLogLog key 的统计值。

#### Geospatial Index 的应用场景？
Geospatial Index 主要用于存储地理位置信息，基于 Sorted Set 实现的，通过 GEO 能够轻松实现两个位置距离的计算、获取指定位置附近的元素等功能。因此它适用于需要管理使用地理空间数据的场景。

#### String 还是 Hash 存储对象数据更好？
String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息以及添加修改字段。String 存储相对来说更加节省空间，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。因此，若对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，可以使用 Hash，否则使用 String。

#### String 的底层实现是什么？
SDS，Simple Dynamic String，简单动态字符串。SDS 共有五种实现方式 `SDS_TYPE_5`（并未用到）、`SDS_TYPE_8`、`SDS_TYPE_16`、`SDS_TYPE_32`、`SDS_TYPE_64`，其中只有后四种实际用到。Redis 会根据初始化的长度决定使用哪种类型，从而减少内存的使用。   
SDS 相比于 C 语言中的字符串有如下提升：
1. 可以避免缓冲区溢出：SDS 被修改时，会先根据 len 属性检查空间大小是否满足要求，如果不满足，则先扩展至所需大小再进行修改操作。
2. 获取字符串长度的复杂度较低：C 语言中的字符串长度需要经过遍历计数实现，而 SDS 长度直接读取 len 属性即可。
3. 减少内存分配次数：为了避免修改（增加/减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）。
4. 二进制安全：C 语言中的字符串以空字符 `\0` 作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 `len` 属性判断字符串是否结束，不存在这个问题。

#### 购物车信息用 String 还是 Hash 比较合适？
由于购物车中的商品频繁修改和变动，购物车信息建议使用 Hash 存储。
- 用户添加商品就是往 Hash 里面增加新的 field 与 value；
- 查询购物车信息就是遍历对应的 Hash；
- 更改商品数量直接修改对应的 value 值（直接 set 或者做运算皆可）；
- 删除商品就是删除 Hash 中对应的 field；
- 清空购物车直接删除对应的 key 即可。

#### 使用 Redis 实现排行榜该怎么做？
Sorted Set。

#### 使用 Set 实现抽奖系统需要什么命令？
- `SADD key member1 member2 ...`：向指定集合添加一个或多个元素。
- `SPOP key count`：随机移除并获取指定集合中一个或多个元素，适合不允许重复中奖的场景。
- `SRANDMEMBER key count`: 随机获取指定集合中指定数量的元素，适合允许重复中奖的场景。

#### 使用 BitMap 统计活跃用户数该怎么做？
可以使用日期（精确到天）作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1。

#### 使用 HyperLogLog 统计 UV 该怎么做？
使用 HyperLogLog 统计页面 UV 主要需要用到下面这两个命令：
- `PFADD key element1 element2 ...`：添加一个或多个元素到 HyperLogLog 中。
- `PFCOUNT key1 key2`：获取一个或者多个 HyperLogLog 的唯一计数。



## Redis 持久化机制

#### Redis 为什么要进行持久化？
主要有两个原因：
1. 为了之后重用数据（比如重启机器、机器故障之后恢复数据）
2. 为了做数据同步（比如 Redis 集群的主从节点通过 RDB 文件同步数据）。

#### Redis 支持几种持久化方式？
- 快照（RDB）
- 只追加文件（append-only-file，AOF）
- RDB 和 AOF 的混合持久化

#### 什么是 RDB 持久化？
通过创建快照将内存中某个时间点的数据复制下来，作为一个副本。    
RDB 是 Redis 默认采用的持久化方式。

#### RDB 创建快照时会阻塞主线程吗？
Redis 提供了两个命令来生成 RDB 快照文件：
- `save` : 同步保存操作，会阻塞 Redis 主线程；
- `bgsave` : `fork` 出一个子进程，子进程执行，不会阻塞 Redis 主线程，默认选项。

#### 什么是 AOF 持久化？
AOF 是只追加文件，就是每次执行更改 Redis 中数据的命令时，将该命令写入 AOF 文件中（注意，先写入到 AOF 缓冲区，再写入系统内核缓冲区，最后刷盘到 AOF 文件）。相比 RDB，AOF 的实时性更好。

#### AOF 工作的基本流程是怎样的？
1. **命令追加(append)**：所有写命令会追加到 AOF 缓冲区中。
2. **文件写入(write)**：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用 `write`，`write` 将数据写入到系统内核缓冲区之后直接返回（延迟写）。
3. **文件同步(fsync)**：AOF 缓冲区根据对应的持久化方法（`fsync` 策略）向硬盘做同步操作。这一步需要调用 `fsync` 函数，`fsync` 针对单个文件操作，对其进行强制硬盘同步，`fsync` 将阻塞直到写入磁盘完成后返回，保证了数据持久化。
4. **文件重写(rewrite)**：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。
5. **重启加载(reload)**：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。

#### AOF 有哪几种刷盘方式(fsync 策略)？
有三种，主要区别在于 `fsync` 同步 AOF 文件的时机（刷盘）：
1. `appendfsync always`：主线程调用 `write` 执行写操作后，后台线程（`aof_fsync` 线程）会立即调用 `fsync` 函数刷盘写入 AOF 文件，`fsync` 完成后线程返回，这样会严重降低 Redis 的性能。
2. `appendfsync everysec`：主线程调用 `write` 执行写操作后立即返回，由后台线程（`aof_fsync` 线程）每秒钟调用 `fsync` 函数同步一次 AOF 文件。
3. `appendfsync no`：主线程调用 `write` 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次。

#### AOF 为什么是在执行完命令之后记录日志的？利弊？
关系型数据库（如 MySQL）通常都是执行命令之前记录日志（方便故障恢复），而 Redis AOF 持久化机制是在执行完命令之后再记录日志。

优点：
- 避免额外的检查开销，AOF 记录日志不会对命令进行语法检查。
- 在命令执行完之后再记录，不会阻塞当前命令的执行。

缺点：
- 如果刚执行完命令 Redis 实例就宕机，会导致对应的修改丢失。
- 可能会阻塞后续其他命令的执行（AOF 记录日志是在 Redis 主线程中进行的）。

#### AOF 重写的过程？
AOF 重写（rewrite） 是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。   
Redis 将 AOF 重写程序放到子进程里执行，避免阻塞 Redis 主线程。   

AOF 文件重写期间，Redis 会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区的所有内容追加到新 AOF 文件末尾，使新 AOF 文件保存的数据库状态与现有数据库状态一致。最后，服务器用新 AOF 文件替换旧的 AOF 文件，以此完成 AOF 文件重写操作。   

AOF 重写可配置触发时机：
- `auto-aof-rewrite-min-size`：如果 AOF 文件大小小于该值，则不会触发 AOF 重写。默认值为 64 MB;
- `auto-aof-rewrite-percentage`：执行 AOF 重写时，当前 AOF 大小（aof_current_size）和上一次重写时 AOF 大小（aof_base_size）的比值。如果当前 AOF 文件大小增加了这个百分比值，将触发 AOF 重写。将此值设置为 0 将禁用自动 AOF 重写。默认值为 100。

#### AOF 校验机制是什么？
AOF 校验机制是 Redis 在启动时对 AOF 文件进行检查，以判断文件是否完整，是否有损坏或者丢失的数据。通过使用 CRC64 算法计算出校验和，再将计算出的校验和与文件末尾保存的校验和进行比较。

#### Redis 4.0 对持久化机制做了什么优化？利弊？
Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。缺点则是 RDB 部分是压缩格式而不是 AOF 格式，可读性较差。

#### RDB 与 AOF 对比，各自的优缺点？
RDB 比 AOF 优秀的地方：
- RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，**文件很小**，适合做数据的备份，灾难恢复。而 AOF 文件记录的是每一次写命令，通常会比 RDB 大很多。
- 使用 RDB 文件恢复数据，直接解析还原数据即可，**速度非常快**。而 AOF 需要依次执行每个写命令，速度非常慢。

AOF 比 RDB 优秀的地方：
- RDB 的数据安全性不如 AOF，没有办法**实时或者秒级持久化数据**。生成 RDB 文件的过程是比较繁重的， 虽然 BGSAVE 子进程写入 RDB 文件的工作不会阻塞主线程，但会对机器的 CPU 资源和内存资源产生影响，严重的情况下甚至会直接把 Redis 服务干宕机。AOF 支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据），仅仅是追加命令到 AOF 文件，操作轻量。
- RDB 文件是以特定的二进制格式保存的，并且在 Redis 版本演进中有多个版本的 RDB，所以存在**老版本的 Redis 服务不兼容新版本的 RDB 格式**的问题。
- AOF 以一种**易于理解和解析**的格式包含所有操作的日志。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题。比如，如果执行 FLUSHALL 命令意外地刷新了所有内容后，只要 AOF 文件没有被重写，删除最新命令并重启即可恢复之前的状态。




## Redis 线程模型

#### Redis 各版本线程模型？
对于读写命令来说，Redis 一直是单线程模型。不过，在 Redis4.0 版本之后引入了多线程来执行一些大键值对的异步删除操作，Redis6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）。

#### Redis 单线程模型？
Redis 单线程并不是说 Redis 内部只有一个线程，而是 Redis 的 Worker 线程是个单线程。比如说有两个客户端分别进行了操作1，操作2，那么 Redis 对于每个操作可能需要 read、计算、write，则 Worker 线程中执行顺序是这样的：`read1 -> 计算1 -> write1 -> read2 -> 计算2 -> write2`。在 Redis6.0 之后，引入了多线程来处理网络请求，也就是将 `read` 和 `write` 放到 IO 子线程中执行，Worker 主线程中只进行了 `计算1 -> 计算2`。     

**Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型**。这套事件处理模型对应的是 Redis 中的文件事件处理器（file event handler）。由于文件事件处理器是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。    

- 文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。
- 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。

文件事件处理器主要包含 4 个部分：
- 多个 socket(客户端连接)
- IO 多路复用程序（支持多个客户端连接的关键）
- 文件事件分派器（将 socket 关联到相应的事件处理器）
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

#### 既然 Redis 是单线程，怎么监听客户端的大量请求？
Redis 通过 **IO 多路复用程序** 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。**I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗**。   

#### Redis 4.0 增加的多线程用于什么的？
Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主线程之外的其他线程来“异步处理”。

#### Redis 6.0 之前为什么不使用多线程？
主要有以下三点原因：
1. 单线程编程容易并且更容易维护；
2. Redis 的性能瓶颈不在 CPU，主要在内存和网络；
3. 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

#### Redis 6.0 之后为什么引入了多线程？
Redis6.0 引入多线程主要是**为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（**Redis 的瓶颈主要受限于内存和网络**）。Redis6.0 的多线程默认是禁用的，只使用主线程。

#### Redis 后台线程有哪些？
- `bio_close_file`：释放 AOF/RDB 等过程中产生的临时文件资源。
- `bio_aof_fsync`：调用 `fsync` 函数将系统内核缓冲区还未同步到磁盘的数据强制刷到磁盘（ AOF 文件）。
- `bio_lazy_free`：释放大对象（已删除）占用的内存空间。



## Redis 内存管理

#### Redis 给缓存数据设置过期时间有啥用？
因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接 `Out of memory`。此外，在一些业务场景比如说验证码的情况下需要设置过期时间，如果使用传统的数据库来处理的话，一般都是自己判断过期，麻烦且性能较差。   

Redis 中除了字符串类型有自己独有设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间 。另外， `persist` 命令可以移除一个键的过期时间。

#### Redis 是如何判断数据是否过期的呢？
Redis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。

#### 过期数据的删除策略有哪些？
1. **惰性删除**：在取出 key 的时候才对数据进行过期检查，对 CPU 友好但可能会导致过多过期 key 没有被删除。
2. **定期删除**：每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。

定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 **定期删除+惰性/懒汉式删除** 。

#### Redis 的内存淘汰机制？
仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就 Out of memory 了。因此要通过 Redis 内存淘汰机制解决这个问题。  

1. `volatile-lru (least recently used)`：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。
2. `volatile-lfu (least frequently used)`：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰。
3. `volatile-ttl`：从已设置过期时间的数据集中挑选将要过期的数据淘汰。
4. `volatile-random`：从已设置过期时间的数据集中任意选择数据淘汰。
5. `allkeys-lru (least recently used)`：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
6. `allkeys-lfu (least frequently used)`：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。
7. `allkeys-random`：从数据集中任意选择数据淘汰。
8. `no-eviction`：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。




## Redis 事务

#### 什么是 Redis 事务？
Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。   

Redis 可以通过 `MULTI`，`EXEC`，`DISCARD` 和 `WATCH` 等命令来实现事务(Transaction)功能。

#### Redis 事务支持原子性吗？
不支持。因为 Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是不支持回滚（roll back）操作的。

#### Redis 事务支持持久性吗？
Redis 支持持久化，但不保证持久性。因为AOF 持久化的fsync策略为 no、everysec 时都会存在数据丢失的情况 。always 下可以基本是可以满足持久性要求的，但性能太差，实际开发过程中不会使用。

#### 如何解决 Redis 事务的缺陷？
可以利用 Lua 脚本。Lua 脚本可以用来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。   

不过，如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，出错之前执行的命令是无法被撤销的，无法实现类似关系型数据库执行失败可以回滚的那种原子性效果。因此， 严格来说的话，**通过 Lua 脚本来批量执行 Redis 命令实际也是不完全满足原子性的**。




## Redis 性能优化

#### RTT 是什么？
RTT，Round Trip Time，即往返时间，也就是数据在网络上传输的时间。

#### 使用批量操作的优点？
使用批量操作可以减少网络传输次数，进而有效减小网络开销，大幅减少 RTT。   
另外，除了能减少 RTT 之外，发送一次命令的 socket I/O 成本也比较高（涉及上下文切换，存在 `read()` 和 `write()` 系统调用），批量操作还可以减少 socket I/O 成本。

#### Redis 原生批量操作命令有哪些？
- MGET：获取一个或多个指定 key 的值
- MSET：设置一个或多个指定 key 的值
- HMGET：获取指定哈希表中一个或者多个指定字段的值
- HMSET：同时将一个或多个 field-value 对设置到指定哈希表中
- SADD：向指定集合添加一个或多个元素

#### MGET 的步骤大概是怎样的？
1. 找到 key 对应的所有哈希槽（hash slot）；
2. 分别向对应的 Redis 节点发起 MGET 请求获取数据；
3. 等待所有请求执行结束，重新组装结果数据，保持跟入参 key 的顺序一致，然后返回结果。

> Redis Cluster 并没有使用一致性哈希，采用的是 **哈希槽分区** ，每一个键值对都属于一个 hash slot（哈希槽） 。当客户端发送命令请求的时候，需要先根据 key 通过上面的计算公示找到的对应的哈希槽，然后再查询哈希槽和节点的映射关系，即可找到目标 Redis 节点。

#### 原生批量操作命令和 pipeline 的区别？
对于不支持批量操作的命令，我们可以利用 pipeline 将一批 Redis 命令封装成一组，这些 Redis 命令会被一次性提交到 Redis 服务器，只需要一次网络传输。不过，需要注意控制一次批量操作的元素个数，避免网络传输的数据量过大。    

原生批量操作命令和 pipeline 的是有区别的，使用的时候需要注意：
1. 原生批量操作命令是原子操作，pipeline 是非原子操作。
2. pipeline 可以打包不同的命令，原生批量操作命令不可以。
3. 原生批量操作命令是 Redis 服务端支持实现的，而 pipeline 需要服务端和客户端的共同实现。

#### Lua 脚本优缺点？
优点：
- 一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰，这是 pipeline 所不具备的。
- Lua 脚本中支持一些简单的逻辑处理比如使用命令读取值并在 Lua 脚本中进行处理，这同样是 pipeline 所不具备的。

缺点：
- 如果 Lua 脚本运行时出错并中途结束，之后的操作不会进行，但是之前已经发生的写操作不会撤销，所以即使使用了 Lua 脚本，也不能实现类似数据库回滚的原子性。
- Redis Cluster 下 Lua 脚本的原子操作也无法保证了，原因同样是无法保证所有的 key 都在同一个 hash slot（哈希槽）上。

#### 大量 key 集中过期问题？解决方案？
定期删除执行过程中，如果突然遇到大量过期 key 的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个定期任务线程是在 Redis 主线程中执行的。这就导致客户端请求没办法被及时处理，响应速度会比较慢。   

解决方法：
1. 给 key 设置随机过期时间。
2. 开启 lazy-free（延迟释放），让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。

#### 什么是 bigkey？bigkey 有什么危害？如何发现 bigkey？
big key：一个 key 对应的 value 所占用的内存比较大。  

bigkey 除了会消耗更多的内存空间和带宽，还会对性能造成比较大的影响。   

发现 big key 的方法：
1. 使用 Redis 自带的 `--bigkeys` 参数来查找。
2. 借助开源工具分析 RDB 文件。
3. 借助公有云的 Redis 分析服务。

#### 如何处理 bigkey？
1. **分割 bigkey**：将一个 bigkey 分割为多个小 key。这种方式需要修改业务层的代码，一般不推荐这样做。
2. **手动清理**。
3. **采用合适的数据结构**：比如使用 HyperLogLog 统计页面 UV。
4. **开启 lazy-free**。

#### hotkey 是什么？危害？如何发现？如何处理？
hot key：访问频繁的 key。hotkey 出现的原因主要是某个热点数据访问量暴增，如重大的热搜事件、参与秒杀的商品。  

处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。此外，如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。   

发现 hot key 的方法：
1. 使用 Redis 自带的 `--hotkeys` 参数来查找，该参数能够返回所有 key 的被访问次数。
2. 使用 `MONITOR` 命令。`MONITOR` 命令是 Redis 提供的一种实时查看 Redis 的所有操作的方式，可以用于临时监控 Redis 实例的操作情况，包括读写、删除等操作。由于该命令对 Redis 性能的影响比较大，因此禁止长时间开启 `MONITOR`。
3. 借助开源工具。
4. 根据业务情况提前预估。
5. 业务代码中记录分析。
6. 借助公有云的 Redis 分析服务。

解决方法：
1. **读写分离**：主节点处理写请求，从节点处理读请求。
2. **使用 Redis Cluster**：将热点数据分散存储在多个 Redis 节点上。
3. **二级缓存**：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）。

#### 什么是内存碎片？
内存碎片可以简单地理解为那些不可用的空闲碎片。比如分配了 32 字节的连续内存空间，而实际存储只用 24 字节，则多出来的 8 字节若后续没办法分配其他数据则为内存碎片。    
Redis 内存碎片不会影响性能，但会增加内存消耗。

#### 为什么会有 Redis 内存碎片？
比较常见的有两个原因：
1. Redis 存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。
2. 频繁修改 Redis 中的数据也会产生内存碎片。当 Redis 中的某个数据删除时，Redis 通常不会轻易释放内存给操作系统。

#### 如何查看 Redis 内存碎片的信息？
使用 `info memory` 命令即可查看 Redis 内存相关的信息。    

Redis 内存碎片率的计算公式：`mem_fragmentation_ratio （内存碎片率）= used_memory_rss (操作系统实际分配给 Redis 的物理内存空间大小)/ used_memory(Redis 内存分配器为了存储数据实际申请使用的内存空间大小)`    
一定不要误认为 `used_memory_rss` 减去 `used_memory` 值就是内存碎片的大小！这不仅包括内存碎片，还包括其他进程开销，以及共享库、堆栈等的开销。

#### 如何清理 Redis 内存碎片？
1. Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。直接通过 `config set` 命令将 `activedefrag` 配置项设置为 `yes` 即可。
2. 重启节点可以做到内存碎片重新整理。



## Redis 生产问题

#### 什么是缓存穿透？如何解决缓存穿透？
缓存穿透是由于大量请求的 key 是不合理的，**根本不存在于缓存中，也不存在于数据库中**，导致请求直接到数据库上，对数据库造成了巨大的压力甚至导致宕机。   

解决方法：
1. **把请求的无效的 key 缓存起来**。
2. **使用布隆过滤器**。把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在**。

#### 什么是缓存击穿？如何解决缓存击穿？
缓存击穿中，请求的 key 对应的是热点数据，该数据 **存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）**。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。   

解决方法：
1. 设置热点数据永不过期或者过期时间比较长。
2. 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀商品。
3. 请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力。

#### 缓存穿透和缓存击穿有什么区别？
缓存穿透中，请求的 key 既不存在于缓存中，也不存在于数据库中。   
缓存击穿中，请求的 key 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）。

#### 缓存雪崩是什么？有哪些解决方法？
缓存雪崩描述的就是这样一个简单的场景：**缓存在同一时间大面积的失效**，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。另外，缓存服务宕机也会导致缓存雪崩现象，导致所有的请求都落到了数据库上。   

解决方法：   
**针对 Redis 服务不可用的情况**：
1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
2. 限流，避免同时处理大量的请求。

**针对热点缓存失效的情况**：
1. 设置不同的失效时间比如随机设置缓存的失效时间。
2. 缓存永不失效（不太推荐，实用性太差）。
3. 设置二级缓存。

#### 缓存雪崩和缓存击穿有什么区别？
缓存雪崩和缓存击穿比较像，但缓存雪崩导致的原因是缓存中的大量或者所有数据失效，缓存击穿导致的原因主要是某个热点数据不存在与缓存中。

#### 如何保证缓存和数据库数据一致？
在旁路缓存模式下：    
旁路缓存模式下遇到写请求是这样的：更新数据库，然后直接删除缓存。    
如果更新数据库成功，而删除缓存失败的话，则可以如下：
1. **缓存失效时间变短（不推荐，治标不治本）**：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。
2. **增加缓存更新重试机制（常用）**：如果缓存服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。





## Redis 常见阻塞问题总结

- **O(n) 命令导致的阻塞**
- **`save` 创建 RDB 快照导致的阻塞**：`save` 是在主线程中备份的。
- **AOF 日志记录阻塞**：AOF 记录日志是在 Redis 主线程中进行的
- **AOF 刷盘阻塞**：当磁盘压力太大的时候，会导致 `fsync` 操作发生阻塞，主线程调用 `write` 函数时也会被阻塞。`fsync` 完成后，主线程执行 `write` 才能成功返回。
- **AOF 重写阻塞**：在将重写缓冲区中内容追加到新 AOF 文件末尾时，有可能会产生阻塞。
- **bigkey 造成的阻塞**：big key 在操作、网络传输、以及删除时，消耗都会比较大，很可能产生阻塞。
- **清空数据库造成的阻塞**：和 big key 是一样的道理。
- **集群扩容缩容造成的阻塞**：在扩缩容的时候，需要进行数据迁移。而 Redis 为了保证迁移的一致性，迁移所有操作都是同步操作。执行迁移时，两端的 Redis 均会进入时长不等的阻塞状态
- **swap 内存交换导致的阻塞**：Redis 保证高性能的一个重要前提是所有的数据在内存中。如果操作系统把 Redis 使用的部分内存换出硬盘，由于内存与硬盘的读写速度差几个数量级，会导致发生交换后的 Redis 性能急剧下降。
- **CPU 竞争导致 Redis 阻塞**：Redis 是典型的 CPU 密集型应用，不建议和其他多核 CPU 密集型服务部署在一起。当其他进程过度消耗 CPU 时，将严重影响 Redis 的吞吐量。
- **网络问题导致的阻塞**：连接拒绝、网络延迟，网卡软中断等网络问题也可能会导致 Redis 阻塞。


