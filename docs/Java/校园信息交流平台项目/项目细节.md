---
title: '项目细节'
---


# 开发平台首页
- discuss_post表中type字段表示是否置顶，0表示不置顶，1表示置顶；status字段表示帖子属于哪种，普通帖0，精华帖1或者拉黑帖2；
- 在查询帖子时，要将拉黑帖屏蔽掉，因此查询条件要添加上 `status!=2`。
- 分页显示帖子，定义 `Page` 类封装分页相关的信息，当前页码 `current` 和每页显示条数是由页面传过来，数据总数 `rows` 则是由数据库返回，查询路径 `path` 则是服务端设置以便下次复用。
- 查询首页的请求到达时，在方法调用前，SpringMVC 会自动实例化 Model 和 Page，并将 Page 注入 Model，所以返回到页面时可以从模板中访问 Page 对象中的数据。

# 开发平台登录模块
- 这里发送邮件相当于起到一个客户端的功能，利用spring自带的 `JavaMailSender` 类实现发送邮件，该类的 `send` 功能参数是一个 `MimeMessage` 对象，该类有一个创建该对象的方法 `createMimeMessage()`。可以利用 `MimeMessageHelper` 类帮助设置 `MimeMessage` 信息。
- 在测试时，没法通过 Controller 层访问到模板文件，所以需要主动创建模板引擎 `TemplateEngine`，用 `process()`方法装填模板位置和数据信息，生成html格式数据作为邮件的内容，再由 `mailClient` 发送邮件。
- 账号设置功能中一个multipartfile只能封装一个文件。


## 注册功能
### 怎么实现注册功能的？（注册过程是怎样的？）
1.用户点击注册按钮向服务器发送申请注册页面请求，服务器响应返回注册的html页面；  
2.用户在注册页面填写好信息，向服务器发送post请求，Controller层接收请求，调用Service层的注册方法；  
3.注册方法首先进行空值处理，判断用户信息是否填写完整，再查询数据库判断用户名和邮箱是否已被注册，这些都没问题才开始注册。除了用户已填写的信息，还需要随机生成5位的随机字符串作为盐拼接到密码末尾再进行md5加密，以及随机生成若干位字符串作为激活码。发送激活邮件：利用 `context` 容器存储注册用户的账号以及存储用户要通过邮箱获取的激活路径，用模板引擎生成格式化的模板，并通过 `mailClient` 的 `sendMail` 方法发送邮件。至此，注册方法结束。   
4.Controller层通过注册方法返回的 Map 判断是否注册过程有错误，若有，将错误信息返回给页面提示用户，若没有，则提醒用户通过邮箱获取激活路径。  
5.用户通过激活路径访问服务器请求激活账户，Controller层调用Service层的激活方法，先判断是否已经激活过，再将页面传过来的激活码与数据库中的比较，若一致则激活成功，更新 User 表中用户的状态，同时清空缓存，否则失败。再将处理结果返回给页面，提示用户。


## 登录退出功能
### 怎么实现登录功能的？（登录过程？）
1.用户请求登录页面，服务器返回 html 登录页面。  
2.用户提交登录页面信息，其中包含了临时凭证 `kaptchaOwner`，服务器 Controller 层从 redis 中取出验证码，跟页面传过来的进行比较，若无误则调用 Service 层的登录方法继续检查账号密码是否正确。  
3.Service 层的登录方法先进行空值处理，再验证账号，若账号密码都正确，则生成登录凭证：自定义 LoginTicket 对象，添加到数据库 login_ticket 表中。（**优化：不用 MySQL 数据库存储登录凭证了，用 redis 存储。**）用 Map 封装处理过程中的错误信息以及登录凭证，作为方法返回值。  
4.通过返回的 map 判断登录是否成功，若成功，则将登录凭证存到 Cookie 中传回客户端，后续的访问请求都需要携带这个 Cookie 作为判断是否登录的依据；若不成功，则返回页面信息提示用户。

### 怎么实现退出功能？
1.将登录凭证修改为失效状态。这一项原本是访问 MySQL 数据库修改 login_ticket 表中数据的，但是优化之后登录凭证是存在了 redis 中的，所以是对 redis 进行操作修改的。
2.跳转至网站首页。

### 怎么生成验证码？
1.用户进入登录页面或者点击图片刷新验证码，则发送验证码请求到服务器。  
2.服务器利用 kaptcha 生成验证码和验证码的图像，这一步需要配置 kaptcha，比如设置图片长宽高、文字的字体颜色、文字候选、文字长度、采用的噪声类。  
3.生成的验证码要存到 session 中，以便再次返回来的时候验证。（**优化：不存到 session 中了，存到 redis中**）
3.服务器为了确定发送过来的验证码属于哪一个用户，对每一个用户都生成了临时凭证 `kaptchaOwner`，存储到了 cookie 中，并设置了 cookie 的存活时间，要在一定时间内验证才有效。  
4.将验证码图片以字节输出流的形式输出到浏览器，因为图像是二进制格式存储的。

### 为什么生成的验证码不存到 session 中了，用 redis 存有什么好处？
验证码之所以要存到 session 中，是为了再次返回时验证。但是，验证码有两个特点，一是需要频繁的访问与刷新，对性能要求较高，二是它不需要永久保存，通常在很短时间后就会失效。  
1.用 Session 虽然也可以存储，但其性能相较于 redis 较低，因为 session 数据的访问通常需要通过服务端的配置文件或数据库进行访问，而 redis 是在内存中的，可以直接通过键值对访问，因此性能较高。   
2.用 Session 和 redis 存储均可以设置过期时间，但是 Session 的设置相对来说麻烦一点。    
3.用 Session 存储的话有一个比较大的问题就是在分布式部署时，存在 Session 共享的问题。举例来说就是当前请求处理中创建了验证码并存储到了 Session 中，但分布式情况下下一次的验证请求有可能会在另一台服务器处理，所以需要将 Session 共享。但是，用 redis 存储就没有共享的问题，因为redis 本身就是数据库，所有的服务器都能访问到。  


## 显示登录信息
### 为什么要显示登录信息？（为什么设置拦截器在每一次请求到达时拦截检查登录凭证？）
因为 http 请求是无状态的，它不会记录之前请求的信息和记录，也就是说每一次请求它都不知道用户之前是否已经登录。而显然，对于用户请求的一些功能是需要登录才能用的，用户的不同级别能够使用的功能也是不同的，所以要在每次请求到达时都拦截下来，取出 Cookie 中的登录凭证来查询用户，并且用线程存储 `ThreadLocal` 的方式存储查询到的用户，以便在本次请求中都持有用户信息以及在请求处理完成后在返回的模板视图 modelAndView 中添加用户信息。注意，在请求结束要清除用户数据。  
（**优化：在取出凭证查询完用户之后，还通过用户 id 查询用户的权限，构建用户认证的结果，并存入 SecurityContext ,以便于 Security 进行授权**）


## 账号设置
### 账号设置包括有哪些功能？包括哪些请求？
账号设置包括**更新头像**和**更新密码**两个功能，分别对应两个请求，但是除此之外，要访问设置页面也需要提供访问设置页面的功能，以及要提供一个给各个页面获取用户头像的功能，这也分别对应了两个请求。  

### 更新头像的过程是怎样的？
1.页面申请访问账号设置页面，服务器返回账号设置页面给浏览器。  
2.页面上传头像给服务端，服务端的 Controller 用 `MultipartFile` 类接收图像，从中获取图像原始文件名，判断后缀格式是否正确。生成随机文件名，用以将图像存储在服务器的本地上传图像目录下，方式是通过 `MultipartFile` 的 `transferTo` 方法。上传文件完成后，更新数据库当前用户的头像的路径。重定向到首页。  
（**优化：文件不存储在本地了，存储在七牛云，减轻服务器的负担**）  

### 页面是怎么获取用户头像的？
1.页面发出请求用户头像的 GET 请求，在请求路径中带有用户头像在服务器本地的存储文件名。  
2.页面从请求路径中提取出头像在本地的文件名，通过服务器存放路径拼接文件名得到该头像的完整文件路径，通过文件输入输出流将图像输出到浏览器（本地图像->服务器程序->浏览器）。  

### 更新密码的过程？
1.页面发送 POST 请求，将原密码和新密码发送到服务器。  
2.服务器进行空值处理，再判断原密码是否与数据库中密码一致，若一致，则更新数据库密码为新密码。返回操作结果页面，并且 model 中携带首页路径作为跳转路径，操作结果页面在显示一段时间后会发送跳转页面请求，服务器响应页面请求，返回页面。

## 检查登录状态
### 为什么要检查登录状态？
有一些功能是需要登录才可以访问的，如果不检查登录状态的话，就会导致没有登录也能访问那些需要登录的功能，这是一件很危险的事情。

### 怎么检查登录状态
1.自定义需要登录的注解 `LoginRequired`（通过元注解定义）  
  - 常用的元注解： `@Target`、`@Retention`、`@Document`、`@Inherited`  
  - 如何读取注解：`Method.getDeclaredAnnotations()`、`Method.getAnnotation(Class<T> annotationClass)`  

2.在需要登录检查的方法上添加这个注解  
3.利用拦截器拦截所有请求，检查请求方法上是否带有该注解，若有，则检查是否登录，如果没登录则直接重定向会登录页面要求用户登录。若方法没有注解或有注解但已登录则会继续往下执行。  


### 显示登录信息和检查登录状态有什么区别？
显示登录信息主要是为了拦截后取得用户的信息，判断用户是否登录；而检查登录状态则是为了检查客户端发出的请求是否需要登录才能获取的。显示登录信息在拦截后无论是否从凭证中查询得到用户信息，请求都继续往下走，而检查登录状态若检查到发出的请求是需要登录才能获取的，且用户此时没有登录，则请求不会继续往下走，而是直接重定向到登录页面要求用户登录。  
（**优化：用Spring Security进行用户授权以及权限不够时的处理，替代检查登录状态功能**）


# 开发社区核心模块
## 过滤敏感词
### 怎么过滤敏感词的？
定义前缀树类（定义叶子节点标志，用Map定义子节点），在敏感词过滤器类(`SensitiveFilter`)加载完初始化的时候构造前缀树，通过类加载器的方式将敏感词文件加载进来，并将每个敏感词添加到前缀树中，前缀树每一条根节点到叶子节点的路径都对应一个敏感词。将要过滤的字符串传进过滤函数，遍历字符串，判断有没有包含前缀树中的完整路径，如果有，则将其替换为过滤词`***`，最终将过滤后的字符串输出。注意：如果文本中敏感词中间有符号，要将符号忽略掉，也就是也要将其作为敏感词过滤掉。

### 为什么读取敏感词文件时要用类加载器的方式读取文件，而不是直接使用输入流？
`this.getClass().getClassLoader().getResourceAsStream()`类加载器方式加载资源，该资源将被缓存在类加载器中，不会被重复加载，可以加快读取速度。而使用输入流虽然可以更灵活地读取文件，但在需要动态加载和卸载资源的情况下，这种方式效率较低，且不易于控制资源的访问和共享。

## 发布帖子
### 怎么发布帖子的？
1.用户点击发布按钮弹出发布信息框，填写完发布的标题和内容，点击提交触发表单 **POST** 请求，浏览器以 **JSON** 数据的格式发送 **AJAX** 异步请求给服务器。  
2.服务器接收 POST 请求，从当前线程中拿到当前请求用户的信息，将帖子和对应用户封装到实体类 `DiscussPost` 中，调用 `HtmlUtil.htmlEscape` 方法转义帖子中的 HTML 标记，以及利用前面实现的过滤敏感词功能对帖子的 `title` 和 `content` 进行过滤，再将过滤后的帖子存到数据库帖子表 `discusspost_post` 中。将处理结果以 JSON 数据的形式返回给浏览器，在方法上方要加注解 `@ResponseBody`，表明返回数据是响应体，而不是页面。  
（**优化一：用 kafka 触发发帖事件，异步提交帖子到 Elasticsearch 数据库**）  
（**优化二：计算新添加的帖子分数，存到Redis里，以便定时任务实现热帖排行**）

## 帖子详情
### 帖子详情有哪些内容？
帖子详情包含了帖子本身，帖子作者，帖子的点赞数量，当前用户对帖子的点赞状态，帖子的评论（对于每一个评论也包含几个内容：评论本身，评论作者，评论的点赞数量，当前用户对该评论的点赞状态，评论的回复（回复也包含了上述的内容））。  
（**优化：点赞数量和点赞状态存在 Redis 里，而不是存在数据库里**）

### 查询帖子详情过程是怎样的？
查询帖子过程并没有什么特殊的地方，只是从数据库中查询数据封装返回给浏览器。需要注意的是在查询过程中各个查询的内容存在哪个数据库中，若是存储在 Redis 中，则 Key 是哪种形式。

## 显示评论
### 评论详情有哪些内容？
评论详情包含了：评论本身，评论的作者，评论的点赞数量，当前用户对该评论的点赞状态，对于本条评论的回复（回复跟评论包含的内容一致，只是评论针对的是帖子，回复针对的是评论）。

### 显示评论过程是怎样的？
该过程也仅是查询数据返回，但是是封装在帖子详情过程中的。需要注意的是，每条评论也有对该评论的回复，也需要封装在该条评论中。

## 添加评论
### 添加评论过程？
1.客户端添加评论，将表单发送给服务器。  
2.服务器用实体类 `Comment` 封装起来，查询当前用户 id 设置为评论的作者，并设置评论的状态和创建时间。与发布帖子类似，也要调用 `HtmlUtil.htmlEscape` 方法转义帖子中的 HTML 标记，以及过滤敏感词功能对评论的 `content` 进行过滤，再将过滤后的评论存到评论表 `comment` 中。  
3.判断添加的评论是对帖子的评论，还是对评论的评论即回复。若是对帖子的评论，还需要更新帖子表 `discuss_post` 中对应帖子的评论数量 `commentCount`。  
4.触发评论事件。判断该评论是对帖子的评论还是对评论的评论，查询对应的实体发布者的用户 id，设置到事件中，以便通知实体发布者有新的评论。  
5.如果该评论是对帖子的评论，还需额外触发发帖事件，异步提交帖子到 Elasticsearch 数据库中，以便在查询时更新帖子。同时，由于新增了评论，还需重新计算帖子的分数，保存到 redis 中。  
（**优化部分：用 kafka 触发事件实现站内通知和更新 Elasticsearch 数据库中帖子，以及实时更新帖子的分数以便实现热帖排行**）  

## 私信列表
### 私信列表功能是怎样的？
私信列表页面跟微信页面很像，都是由该用户与其他人的会话组成，在页面只显示每个会话的最新一条私信，并且列表支持分页显示。  

### 私信列表功能是怎么实现的？
1.客户端用户点击私信列表功能，发送 `GET` 请求到服务器，请求中携带着当前分页的参数。    
2.服务器查询用户在当前分页的会话以及每个会话的最新私信。再通过查询，将每个会话的私信总数、相应的未读私信数、以及会话另一侧的用户与会话封装起来存进模板 `Model` 中返回给页面。同时，要将用户的总未读私信数和总未读通知数也返回给页面，以便在页面私信功能处和通知功能处显示。  
3.由于总未读数（总未读私信数 + 总未读通知数）要显示在平台最顶端，也就是说在任何一个页面都要显示，因此设置了一个拦截器 `MessageInterceptor`，在用户任何请求处理完成后拦截下来，在 `ModelAndView` 中添加这个属性 `allUnreadCount`。

### 在查询私信的功能是有哪些注意的地方？
1.对于用户的一个会话，用户既可能是发送方，也可能是接收方，但不管是哪一个，都属于同一个会话，因此在查询时条件为 `from_id = #{userId} or to_id = #{userId}` ，而相应的会话 id 则是根据双方的用户 id 组成的，由小到大，如 `112_114`。  
2.查询条件中 `from_id != 1` 则是表示私信的发送者不能是系统用户，因为由系统用户所发的私信是属于通知，而且用户是无法发送给系统用户的。  
3.查询条件中 `status != 2` 则是表示该私信不能是删除状态的，因为在数据库中所存储的数据，我们只是进行逻辑删除，即将其状态改为删除状态，而不是真的删除了这条数据。（注：**0 为未读状态，1 为已读状态，2 为删除状态**）

## 私信详情
### 查询私信详情的实现过程？
1.用户点击会话，请求会话详情页面，请求中携带着会话 id 和分页参数。  
2.服务器将分页参数封装进分页实体，查询得到该会话的在当前页数的所有私信，同时查询每条私信的发送者（可能是当前用户，也可能是会话另一侧用户），封装起来，存到 `Model` 中。查询会话的另一侧用户，也存到 `Model` 中，以便显示。   
3.将当前会话的所有未读状态的私信都更新为已读状态。  

## 发送私信
### 发送私信过程？
1.用户点击“发送私信”功能，弹出发送私信框，输入接收者的名字和发送的内容，**异步发送**提交给服务器。  
2.服务器接收参数后，通过名字查询私信接收者，判断是否存在，若存在则设置私信的各项内容，其中会话 id 是由双方的用户 id 组成的。将设置好的私信存入到数据库中的私信表 `message` 中。  

## 统一处理异常
### 异常的传递路径？
在请求的处理过程中，方法的调用通常是这样的：**Controller层 -> Service层 -> DAO层**。而为了统一处理异常，我们是将异常的处理放在了最上层，也就是在 Controller 层处理。若是在 Service 层和 DAO 层出现异常，则我们直接将异常抛出，等到了 Controller 层再处理。

### 如何在 Controller 层处理异常？
利用 Spring 的全局异常处理方式 `@ControllerAdvice` 和对应的方法注解 `@ExceptionHandler` 来处理。通过自定义类和方法，加上这两个注解，可以捕获在 Controller 层抛出的异常，并进行处理。处理流程如下：  
1.由于抛出了异常，要在日志中记录下来。  
2.根据请求中请求头 `x-requested-with` 的值是否是 `XMLHttpRequest` 判断当前请求是否是异步请求。  
3.若是异步请求，则返回 JSON 数据，通过 `Writer` 输出，告诉浏览器服务器出现问题。若不是异步请求，则重定向到请求错误页面，返回错误页面给浏览器。

### @ControllerAdvice 是怎么工作的？
`@ControllerAdvice` 本质上是一个 `@Component`，会被当成组件扫描，用于修饰类，表示该类是 Controller 的全局配置类。它是 AOP 思想的一种实现，通过搭配 `@ExceptionHandler`、`@ModelAttribute`、`@DataBinder` 这三个注解可以对 Controller 进行三种全局配置：异常处理方案、绑定数据方案、绑定参数方案。
- @ExceptionHandler
  - 用于修饰方法，该方法会在Controller出现异常后被调用，用于处理捕获到的异常。
- @ModelAttribute
  - 用于修饰方法，该方法会在Controller方法执行前被调用，用于为Model对象绑定参数。
- @DataBinder
  - 用于修饰方法，该方法会在Controller方法执行前被调用，用于绑定参数的转换器。

**注意：首先，`@ControllerAdvice` 虽然是 AOP 思想的一种实现，但并非使用常规的 AOP 方式来织入业务逻辑的，而是 Spring 内置对其各个逻辑的织入方式进行了内置支持。其次，三个方法注解若是应用于`@ControllerAdvice` 所标注的类中，那么它们表示会对 `@ControllerAdvice` 所指定的范围内的接口都有效；若是单纯的将这三种注解应用于某个 Controller 中，那么它们将只会对该 Controller 中全部的接口有效，而且此时是不须要在该 Controller 上标注 `@ControllerAdvice` 的。**

## 统一记录日志
### 统一记录日志功能是记录什么？
在用户访问任何业务组件之前，即访问 Service 层的方法之前，记录用户 ip，访问的时间，要访问的方法。输出到日志中，即为 `用户[1.2.3.4],在[xxx],访问了[com.nowcoder.community.service.xxx()]`。

### 怎么实现统一记录日志的？
利用 Spring AOP 实现业务逻辑织入。  
1.自定义一个统一记录日志的类，加上 `@Aspect` 注解表明该类作为 **切面**。  
2.定义**切点**为 Service 层的所有方法，`@Pointcut("execution(* com.nowcoder.community.service.*.*(..))")`。  
3.定义**通知**，声明在切点哪个状态时织入，有五个状态：`@Before`、`@After`、`@AfterReturning`、`@AfterThrowing`、`@Around`。这里是要在访问之前记录，因此是 `@Before`。  
4.在要织入的业务逻辑方法中，要得到三个东西：用户ip，当前时间，访问的方法  
4.1 **用户ip**：通过 `RequestContextHolder.getRequestAttributes().getRequest()` 方法获得 `HttpServletRequest`，再调用其 `getRemoteHost()` 方法获得用户的 ip 地址。  
4.2 **当前时间**：直接 `new Date()` 即可。  
4.3 **访问的方法**：从切点属性中获得签名 `joinPoint.getSignature()`，再从签名中获得方法的类地址 `getDeclaringTypeName()` 和方法名 `getName()`。  

### AOP 的一些八股
- AOP的概念
  - Aspect Oriented Programing，即面向方面（切面）编程
  - AOP是一种编程思想，是对OOP的补充，可以进一步提高编程的效率。
- AOP的实现
  - AspectJ
    - AspectJ是语言级的实现，它扩展了Java语言，定义了AOP语法。
    - AspectJ在编译期织入代码，它有一个专门的编译器，用来生成遵守Java字节码规范的class文件。
  - Spring AOP
    - Spring AOP使用纯Java实现，它不需要专门的编译过程，也不需要特殊的类装载器。
    - Spring AOP在运行时通过代理的方式织入代码，只支持方法类型的连接点
    - Spring支持对AspectJ的集成。
- Spring AOP
  - JDK动态代理
    - Java提供的动态代理技术，可以在运行时创建接口的代理实例。
    - Spring AOP默认采用此种方式，在接口的代理实例中织入代码。
  - CGLib动态代理
    - 采用底层的字节码技术，在运行时创建子类代理实例。
    - 当目标对象不存在接口时，Spring AOP会采用此种方式，在子类实例中织入代码

# Redis，一站式高性能存储方案
## 点赞
### 点赞的对象有哪些，需要实现哪些功能？
点赞的对象包括了各个实体，也就是帖子、评论、用户。  
实现的功能：点赞、查询某实体收获的点赞数量、某人对某实体的点赞状态、查询某个用户获得的赞   
- 点赞：支持当前用户对实体点赞，第一次是点赞，第二次是取消点赞。点赞时不仅需要将该用户加入实体收获的点赞来源中，还需要将实体对应的用户收获的赞加一，取消点赞则相反。因此需要用 redis 事务做一个统一的操作。（**优化：在点赞完成后，要触发相应的点赞事件，通知被点赞的用户；若点赞的实体是帖子，该帖子的分数也会发生变化，因此要将其加入 Redis 中需要重新计算分数的帖子列表**）
- 某实体收获的点赞数量：计算实体收获的点赞来源的个数。
- 某人对某实体的点赞状态：判断用户 id 是否在实体收获的点赞来源中。
- 查询某个用户获得的赞：直接查询对应的 key。

> 除了点赞功能之外，对于后面三个实际上用在各个页面上的，在需要显示的地方直接调用对应的 Service 方法即可。

### 这一部分功能在 Redis 中存储的 key 和 value 是什么形式？
某个实体收获的点赞来源：Key：`like:entity:entityType:entityId`，value：`usedId`   
某个用户收获的点赞数量：Key：`like:user:userId`，value：`int`   
> 某个用户收获的点赞数量可以由实体收获的点赞来源统计出来，但是，由于我们并不需要记住用户收获的点赞来自哪些用户，只需要记住有多少个人给该用户点赞即可，因此直接用另一个 key 存储，查询更新也更快速。


## 关注、取消关注
### 关注的逻辑是怎样的？
- 逻辑：若A关注了B，则A是B的 Follower (粉丝)，B是A的 Followee (关注目标)
- 关注的目标可以是用户、帖子、题目等，在实现时将这些目标抽象为实体

### 这一部分功能在 Redis 中存储的 key 和 value 是什么形式？
某个用户的关注目标实体：Key：`followee:userId:entityType`，value：`usedId`   
某个实体拥有的粉丝：Key：`follower:entityType:entityId`，value：`usedId`   

### 关注和取消关注是怎么实现的？
关注既需要在当前用户的关注目标中添加关注的实体，又需要在关注的实体的粉丝列表中添加当前用户，因此需要用 Redis 的事务做一个统一的操作，而取消关注则相反。（**优化：若是关注，则还需要额外触发关注的事件，通知被关注的实体的对应用户**）

### 获得关注目标列表和获得粉丝列表怎么实现？
查询 Redis 中的对应的 key 即可，此外，在查询得到关注目标列表或者粉丝列表后，需要判断该用户是否也被对方关注或者关注了对方，即双方是否是相互关注的。

## 优化登录模块
### 为什么使用Redis存储验证码，来代替 Session？
验证码之所以要存到 session 中，是为了再次返回时验证。但是，验证码有两个特点，一是需要频繁的访问与刷新，对性能要求较高，二是它不需要永久保存，通常在很短时间后就会失效。  
1.用 Session 虽然也可以存储，但其性能相较于 redis 较低，因为 session 数据的访问通常需要通过服务端的配置文件或数据库进行访问，而 redis 是在内存中的，可以直接通过键值对访问，因此性能较高。   
2.用 Session 和 redis 存储均可以设置过期时间，但是 Session 的设置相对来说麻烦一点。    
3.用 Session 存储的话有一个比较大的问题就是在分布式部署时，存在 Session 共享的问题。举例来说就是当前请求处理中创建了验证码并存储到了 Session 中，但分布式情况下下一次的验证请求有可能会在另一台服务器处理，所以需要将 Session 共享。但是，用 redis 存储就没有共享的问题，因为redis 本身就是数据库，所有的服务器都能访问到。  

### 为什么使用 Redis 存储登录凭证，而不是存储在 MySQL 中？
登录凭证是用来查询用户信息的，每次请求都需要查询，它与验证码的特点很像，一是需要频繁的访问与刷新，对性能要求较高，二是它不需要永久保存，通常在一段时间后就会失效。  
1.Redis 是存储在内存中的，存取速度很快，性能很高，用 MySQL 也可以存储，但性能相较于 redis 较低。  
2.用 MySQL 存储判断过期时间需要自定义判断，比较麻烦，而 Redis 则可以在存储时设置，比较方便。

### 为什么要使用 Redis 缓存用户信息，不是可以直接访问数据库查询吗？
处理每次请求时，都要根据凭证查询用户信息，访问的频率非常高。用 Redis 缓存用户信息，则不用每次请求都访问 MySQL 数据库，减轻了数据库的负担，且性能较快。  

### 用 Redis 缓存用户信息后，服务器查询用户的过程发生了什么变化？
在没有用 Redis 缓存用户信息之前，都是直接根据用户 id 查询数据库。  
当用了 Redis 缓存后，服务器优先从缓存中查询，查询到了则直接返回，若查询不到则从数据库查询并缓存到 Redis 中，再返回。此外，由于用了缓存，因此用户数据发生变更时，比如更新头像，除了要更新 MySQL 中的用户数据，还要将 Redis 中对应的用户数据清除掉。（**旁路缓存策略**）


# Kafka，构建TB级异步消息系统



# 开发平台搜索功能




# 项目优化
## 权限控制
- 登录检查
  - 之前采用拦截器实现了登录检查，这是简单的权限管理方案，现在将其废弃
- 授权配置
  - 对当前系统内包含的所有的请求，分配访问权限（普通用户、版主、管理员）
- 认证方案
  - 绕过Security认证流程，采用系统原来的认证方案
- CSRF配置
  - 防止CSRF攻击的基本原理，以及表单、AJAX相关的配置

### 什么是 CSRF 攻击？原理是什么？
1.CSRF（Cross-site request forgery），中文名称：跨站请求伪造，也被称为：one click attack/session riding，缩写为：CSRF/XSRF。简单地说，是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并运行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过，所以被访问的网站会认为是真正的用户操作而去运行。这利用了 web 中用户身份验证的一个漏洞：简单的身份验证只能保证请求发自某个用户的浏览器，却不能保证请求本身是用户自愿发出的。  
2.CSRF一般的攻击原理是，攻击者向目标网站注入一个恶意的CSRF攻击URL地址(跨站url)，当(登录)用户访问某特定网页时，如果用户点击了该URL，那么攻击就触发了，我们可以在该恶意的url对应的网页中，来向目标网站发生一个get请求，该请求会携带cookie信息，所以也就借用了用户的身份，也就是伪造了一个请求，该请求可以是目标网站中的用户有权限访问的任意请求。也可以使用javascript构造一个提交表单的post请求。比如构造一个转账的post请求。  
3.攻击过程：  
（1）用户 C 打开浏览器，访问受信任网站 A，输入用户名和密码请求登录网站 A；  
（2）在用户信息通过验证后，网站 A 产生 Cookie 信息并返回给浏览器，此时用户登录网站 A 成功，可以正常发送请求到网站 A；  
（3）用户未退出网站 A 之前，在同一浏览器中，打开一个 TAB 页访问网站 B；  
（4）网站 B 接收到用户请求后，返回一些攻击性代码，并发出一个请求要求访问第三方站点 A；  
（5）浏览器在接收到这些攻击性代码后，根据网站 B 的请求，在用户不知情的情况下携带 Cookie 信息，向网站 A 发出请求。网站 A 并不知道该请求其实是由 B 发起的，所以会根据用户 C 的 Cookie 信息以 C 的权限处理该请求，导致来自网站 B 的恶意代码被执行。

### 怎么防御 CSRF 攻击？
CSRF的防御可以从服务端和客户端两方面着手，防御效果是从服务端着手效果比较好，现在一般的 CSRF 防御也都在服务端进行。服务端的CSRF方式方法很多样，但总的思想都是一致的，就是在客户端页面增加伪随机数。  
（1）Cookie Hashing(所有表单都包含同一个伪随机值)：最简单，但不够安全。  
（2）加验证码，强制用户必须与应用进行交互，才能完成最终请求。安全，但不够实用。  
（3）Anti CSRF Token：现在业界的一致做法。每一个网页包含一个 web server 产生的 token,提交时，也将该 token 提交到服务器，服务器进行判断，如果 token 不对，就判定为 CSRF 攻击。这个 Token 的值必须是随机的，不可预测的。由于 Token 的存在，攻击者无法再构造一个带有合法 Token 的请求实施 CSRF 攻击。另外使用 Token 时应注意 Token 的保密性，尽量把敏感操作由 GET 改为 POST，以 form 或 AJAX 形式提交，避免 Token 泄露。

### 项目中是怎么防御 CSRF 攻击的？
利用 Spring Security 进行防御，Spring Security 提供了令牌同步模式来防止 CSRF 攻击，也就是上面所说的 Anti CSRF Token 的方式。具体的操作方式就是在每一个HTTP请求中，除了默认自动携带的Cookie参数之外，再提供一个安全的、随机生成的宇符串，我们称之为CSRF令牌。这个CSRF令牌由服务端生成，生成后在HttpSession中保存一份。当前端请求到达后，将请求携带的CSRF令牌信息和服务端中保存的令牌进行对比，如果两者不相等，则拒绝掉该HTTP请求。


## 置顶、加精、删除
- 功能实现
  - 点击置顶，修改帖子的类型
  - 点击 “加精”、“删除”， 修改帖子的状态。
- 权限管理
  - 版主可以执行“置顶”、“加精”操作
  - 管理员可以执行“删除”操作
- 按钮显示
  - 版主可以看到“置顶”、“加精”按钮
  - 管理员可以看到“删除”按钮

### 置顶加精删除的流程？
1.这三个功能是需要一定权限才可以访问的，浏览器访问这几个功能。  
2.更新服务器中帖子的类型或状态，同时触发对应的事件，由 kafka 异步进行消息处理。  
3.在加精时，由于帖子分数也改变了，所以需要将帖子添加到 redis 中待重新计算的帖子列表中，等待定时任务重新计算帖子分数。  
4.返回处理结果（JSON数据）给浏览器。


## 网页数据统计
### 网页数据统计有哪两个功能？
UV (Unique Visitor) 独立访客和 DAU (Daily Active User) 日活跃用户

### UV 怎么统计的？
1.在每次请求访问到达时，先用拦截器拦截请求，通过 `request` 得到用户的 ip，计入当日 UV。   
2.UV 是用 redis 的 HyperLogLog 类型记录，若是指定日期范围内的 UV，则需要将这段日期内的单日 UV 联合起来。在获取这段时间内的单日 UV key 集合时，用日历类型 `Calendar` 遍历得到 keyList。  

### 为什么要用 HyperLogLog 统计 UV？
因为 HyperLogLog 可以用来近似统计，效率非常高，性能好，且存储空间小。

### DAU 怎么统计的？
1.在每次请求访问到达时，先用拦截器拦截请求，从当前线程中获取用户信息，计入当日 DAU。  
2.DAU 是用 redis 的 Bitmap 类型记录，若是用户登录访问了，则将当日 DAU 中该用户对应的位设置为 true。若是要统计指定日期范围内的 DAU，则需要将这段日期内的单日 DAU 联合起来，具体是进行或运算 OR，即这段日期内只要有一天活跃则视为活跃。在获取这段时间内的单日 DAU key 集合时，用日历类型 `Calendar` 遍历得到 keyList。

### 为什么要用 Bitmap 统计 DAU？
因为 DAU 需要比较精确的统计，而 redis 的 Bitmap 类型则提供了这样的功能，且其性能好。同时，每个位代表一个用户，所以可以比较简单地排重。


## 热帖排行
### 帖子分数是怎么计算的？
计算公式：log(精华分 + 评论数\*10 + 点赞数\*2) + （发布时间 - 牛客纪元）

### 帖子分数的更新过程是实时的吗？更新过程是怎样的？
帖子分数的更新不是实时的，是采用定时任务来实现的，而且定时任务只处理分数变化的帖子。这些分数变化的帖子集合是存储在 redis 中的，用 set 存储。每隔一段时间（项目中设置为 3 秒），quartz 就会执行定时任务，将 set 中的帖子分数更新，同时也同步到 elasticsearch 的数据库。

### 有哪些可以实现定时任务的工具？
JDK 可执行定时任务的线程池：ScheduledExecutorService  
Spring 可执行定时任务的线程池：ThreadPoolTaskScheduler  
分布式定时任务工具 Spring Quartz

### JDK 线程池和 Spring 线程池的区别？
JDK 线程池和 Spring 线程池都各有普通的线程池和可执行定时任务的线程池。
- JDK 线程池(**面试重点**)
  - 普通线程池：ExecutorService
  - 可执行定时任务的线程池：ScheduledExecutorService
- Spring 线程池(**面试重点**)（不在分布式环境下的话推荐使用spring提供的）
  - Spring普通线程池：ThreadPoolTaskExecutor,有简化使用方式：注解方式：@Async
  - Spring可执行定时任务的线程池：ThreadPoolTaskScheduler（没有解决分布式情况下冲突的问题）,也有简化使用方式：注解：@Scheduled

### Quartz 实现定时任务应该如何配置？
主要就是要实现 Job 接口以定义任务，以及配置 JobDetail 和 Trigger 两个 Bean。JobDetail 用来配置 Job；Trigger 用来配置Job什么时候运行，以什么样频率执行任务。  

- Spring Quartz：需要在数据库里存入一些信息（一些表）
  - 核心组件：Scheduler接口（需要定义任务）、Job接口（定义一个任务）、JobDetail接口（用来配置Job）、Trigger接口（用来配置Job什么时候运行，以什么样频率执行任务）
  - 配置完后程序启动时Quartz会读取配置信息，存到数据库里(需配置properties文件，数据库里的表：`qrtz_job_details、qrtz_simple_trigger、qrtz_triggers、qrtz_scheduler_state、qrtz_locks`)，后面Quartz就直接读取数据库来执行任务，不需要重新配置


## 生成长图



## 将文件上传至云服务器




## 二级缓存，优化网站性能
### 多级缓存形式是怎样的？为什么要用多级缓存？
\> 一级缓存（本地缓存） \> 二级缓存（分布式缓存） \> DB  
使用多级缓存能够避免缓存雪崩（缓存失效，大量请求直达DB），提高系统的可用性。  

### 有哪些缓存工具？
一级缓存（本地缓存）：Ehcache、Guava、Caffeine等  
二级缓存（分布式缓存）：MemCache、Redis等  

### 本地缓存和分布式缓存各自的优缺点？
本地缓存：将数据缓存在应用服务器上，**性能最好**，但是无法跨服务器，在分布式情况下有存在数据共享问题。  
分布式缓存：将数据缓存在 NoSQL 数据库上，**能够跨服务器**，性能比本地缓存稍低一些。  

### 项目中用多级缓存来缓存什么？
项目中用多级缓存来缓存热门帖子，优化热门帖子列表。

### 为什么要优化热门帖子列表，而没有优化按时间排序的帖子列表？
因为缓存适用于变化频率比较小的情况，而按时间排序的帖子列表随发帖变化而变化，数据变化频繁。  
而热门帖子列表是按帖子分数排的，且帖子分数是按定时任务每隔一段时间才计算的，所以在这段时间内，热门帖子基本是不变的，所以适合用多级缓存。

### Ehcache、Guava、Caffeine等都可以用 Spring 整合，为什么不用？
因为 Spring 整合是用一个 cacheManager 去管理所有的缓存，而程序可能有很多的缓存，比如 A 可以缓存帖子，B 可以缓存其他数据。而 Spring 用的 cacheManager 所进行的缓存设置是针对所有缓存的，这样不太合适，因为每个缓存的场景不同，设置也有所区别。所以项目中用的 Caffeine 是单独使用的，可以在 github 搜索手册，在 maven repository 网站搜索包。

### Caffeine 简介？
Caffeine 是仿造 Guava 的，使用方式基本相同，但是其是用最新的算法，所以性能要优于 Guava，现在更加流行一些。  

### Caffeine 如何使用？
1.在 properties 中进行一些配置，配置缓存的最大页数，以及缓存过期时间。  
2.Caffeine 核心接口：Cache。它有两个子接口：LoadingCache, AsyncLoadingCache（异步的，支持并发的）  
3.项目中利用 LoadingCache 缓存帖子列表：`private LoadingCache<String, List<DiscussPost>> postListCache;`，以及缓存帖子总数：`private LoadingCache<Integer, Integer> postRowsCache;`。之所以是这种形式，是因为缓存基本上都是以 key-value 的形式来存储的。    
4.初始化缓存：初始化帖子列表缓存，初始化帖子总数缓存。初始化的方式是固定的，可以从官网中拷贝。要读取在 properties 中的参数进行设置，以及通过 CacheLoader 的 load 方法设置 Caffeine 的缓存来源，数据从哪里来的。  
5.由于项目中热门帖子都会在 `Service` 层被调用，因此在 `DiscussPostService` 中进行缓存处理。当查询热门帖子时才从缓存中取。  

### 怎么验证多级缓存的效果？
做压力测试。

### 怎么用 Jmeter 做压力测试？
1.下载 apache 的 Jmeter 的压缩包，解压就能用了。在 bin 目录下双击 Jmeter.bat 就可以启动。  
2.要设置测试计划。新建测试计划，添加 -> 线程 -> 线程组，之所以用线程组，是因为要模拟大量的请求访问数据库，所以用线程组才能测试并发的能力。测试时设置的线程为 100，在一秒内创建完成，线程组持续时间为 60 秒。  
3.在线程组内添加取样器 -> HTTP 请求，设置为访问项目的热门帖子。  
4.线程组再添加一个统一随机定时器。如果没有添加定时器，线程组就没有间隔地去访问服务器，很快服务器就会瘫痪，所以添加一个随机定时器来间隔一下请求。  
5.添加一个监听器 -> 聚合报告。测试结果可以从聚合报告看出，主要看**吞吐量**（每一秒服务器可以处理多少个请求）  
6.项目中，若没有添加二级缓存，即优化前，吞吐量为 9.5/sec 所有。若添加了二级缓存，即优化后，吞吐量为 188.9/sec。性能大概差了 18 倍。


# 优化的点
- 登录凭证不用 MySQL 数据库存储，用 redis 存储
- 验证码不用 Session 存储，用 redis 存储
- 在拦截检查登录凭证显示用户信息后，还通过查询用户权限构建用户认证的结果，并存入 SecurityContext ，以便于 Security 进行授权。若用户不够权限，则会进行处理，这一步实际上就替代了检查登录状态功能。
- 头像文件不存储在服务器本地，而是存储在七牛云，不需要这部分的空间了，而且获取头像不需要访问服务器了，减轻了服务器的负担。
- 发布帖子时，用 kafka 触发发帖事件，异步提交帖子到 Elasticsearch 数据库，以便搜索功能；计算新添加的帖子分数，存到Redis里，以便定时任务实现热帖排行。
- 点赞数量和点赞状态存在 Redis 里，而不是存在数据库里。**为什么？**
- 添加评论时利用 kafka 实现站内通知和更新 Elasticsearch 数据库，以便更新查询，同时实时更新帖子分数以便实现热帖排行。
- 在点赞完成后，要触发相应的点赞事件，通知被点赞的用户；若点赞的实体是帖子，该帖子的分数也会发生变化，因此要将其加入 Redis 中需要重新计算分数的帖子列表。
- 使用 Caffeine 和 Redis 组合成二级缓存，优化网站性能。